{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Uncertainty-Aware Domain Adaptation for Plant Disease Detection**\n",
        "\n",
        "\n",
        "This notebook implements the complete pipeline from data preparation through training to evaluation."
      ],
      "metadata": {
        "id": "K0KgpofaAjVQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHpWMF7wAbpz",
        "outputId": "9f921311-d51e-4c21-9c81-dfb53713e417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU Device: Tesla T4\n",
            "GPU Memory: 15.828320256 GB\n",
            "\n",
            "Setup completed successfully!\n",
            "\n",
            "Directories created successfully\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 1: SETUP AND INSTALLATIONS\n",
        "# ============================================================================\n",
        "\n",
        "import torch\n",
        "import os\n",
        "# Install required packages and check GPU availability\n",
        "# Check GPU\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Device:\", torch.cuda.get_device_name(0))\n",
        "    print(\"GPU Memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n",
        "\n",
        "print(\"\\nSetup completed successfully!\")\n",
        "\n",
        "os.makedirs('./checkpoints', exist_ok=True)\n",
        "os.makedirs('./results', exist_ok=True)\n",
        "print(\"\\nDirectories created successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading Dataset from Kaggle"
      ],
      "metadata": {
        "id": "HuEGdSbYAyqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usually pre-installed in Colab, but just in case\n",
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"üìÅ Please upload your kaggle.json file\")\n",
        "print(\"(You can download it from Kaggle.com ‚Üí Settings ‚Üí API ‚Üí Create New Token)\")\n",
        "print()\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Setup Kaggle\n",
        "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"\\n Kaggle credentials successfully configured!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "I91KLyf6A0OB",
        "outputId": "ce311dcc-4ea6-405d-feb8-e18e49ac6390"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Please upload your kaggle.json file\n",
            "(You can download it from Kaggle.com ‚Üí Settings ‚Üí API ‚Üí Create New Token)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3545e978-a87f-4c98-a9d9-c2fa57cdf743\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3545e978-a87f-4c98-a9d9-c2fa57cdf743\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "\n",
            " Kaggle credentials successfully configured!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test if Kaggle API is working\n",
        "!kaggle datasets list | head -5\n",
        "\n",
        "print(\"\\n‚úì Kaggle API is working!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA7xMF8UA-4J",
        "outputId": "825e0004-3762-4a7b-f269-c1c1533536a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                           title                                                    size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------------  -------------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
            "ahmadrazakashif/bmw-worldwide-sales-records-20102024          BMW Worldwide Sales Records (2010‚Äì2024)                853348  2025-09-20 14:39:45.280000           7762        168  1.0              \n",
            "jockeroika/life-style-data                                    Life Style Data                                       6289184  2025-10-13 02:11:38.793000           2239         62  0.9411765        \n",
            "grandmaster07/student-exam-score-dataset-analysis             Student exam score dataset analysis                      2430  2025-09-26 07:44:12.677000           3215         72  1.0              \n",
            "\n",
            "‚úì Kaggle API is working!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PlantDoc Dataset**\n",
        "available at [PlantDoc Classification dataset](https://www.kaggle.com/datasets/nirmalsankalana/plantdoc-dataset)"
      ],
      "metadata": {
        "id": "FZmB6DaeBAtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\" Downloading PlantDoc dataset...\")\n",
        "print(\"Dataset: nirmalsankalana/plantdoc-dataset\")\n",
        "print()\n",
        "\n",
        "# Download\n",
        "!kaggle datasets download -d nirmalsankalana/plantdoc-dataset\n",
        "\n",
        "print(\"\\n‚úì Download complete!\")\n",
        "\n",
        "# Check file size\n",
        "!ls -lh plantdoc-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-uknyh_BHuJ",
        "outputId": "baf6ccd4-7afd-40a2-b7c8-9045fb65ca30"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Downloading PlantDoc dataset...\n",
            "Dataset: nirmalsankalana/plantdoc-dataset\n",
            "\n",
            "Dataset URL: https://www.kaggle.com/datasets/nirmalsankalana/plantdoc-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading plantdoc-dataset.zip to /content\n",
            "100% 894M/896M [00:07<00:00, 116MB/s] \n",
            "100% 896M/896M [00:07<00:00, 119MB/s]\n",
            "\n",
            "‚úì Download complete!\n",
            "-rw-r--r-- 1 root root 896M Sep 16  2024 plantdoc-dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üì¶ Extracting dataset...\")\n",
        "\n",
        "# Create directory and extract\n",
        "!mkdir -p /content/plantdoc\n",
        "!unzip -q plantdoc-dataset.zip -d /content/plantdoc\n",
        "\n",
        "print(\"‚úì Extraction complete!\")\n",
        "\n",
        "# Verify structure\n",
        "print(\"\\nüìÇ Dataset structure:\")\n",
        "!ls -lh /content/plantdoc\n",
        "\n",
        "print(\"\\nüìÇ Train folder:\")\n",
        "!ls /content/plantdoc/train | head -10\n",
        "\n",
        "print(\"\\nüìÇ Test folder:\")\n",
        "!ls /content/plantdoc/test | head -10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IKyr0nqBQmI",
        "outputId": "e95e3b9b-b51e-4594-83dd-c389b2a5445c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Extracting dataset...\n",
            "‚úì Extraction complete!\n",
            "\n",
            "üìÇ Dataset structure:\n",
            "total 16K\n",
            "-rw-r--r--  1 root root 1.2K Sep 16  2024 file_renamer.py\n",
            "-rw-r--r--  1 root root  595 Sep 16  2024 folder_renamer.py\n",
            "drwxr-xr-x 29 root root 4.0K Oct 27 08:47 test\n",
            "drwxr-xr-x 30 root root 4.0K Oct 27 08:47 train\n",
            "\n",
            "üìÇ Train folder:\n",
            "Apple_leaf\n",
            "Apple_rust_leaf\n",
            "Apple_Scab_Leaf\n",
            "Bell_pepper_leaf\n",
            "Bell_pepper_leaf_spot\n",
            "Blueberry_leaf\n",
            "Cherry_leaf\n",
            "Corn_Gray_leaf_spot\n",
            "Corn_leaf_blight\n",
            "Corn_rust_leaf\n",
            "\n",
            "üìÇ Test folder:\n",
            "Apple_leaf\n",
            "Apple_rust_leaf\n",
            "Apple_Scab_Leaf\n",
            "Bell_pepper_leaf\n",
            "Bell_pepper_leaf_spot\n",
            "Blueberry_leaf\n",
            "Cherry_leaf\n",
            "Corn_Gray_leaf_spot\n",
            "Corn_leaf_blight\n",
            "Corn_rust_leaf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PlantVillage Dataset**\n",
        "available at [PlantVillage](https://www.kaggle.com/datasets/mohitsingh1804/plantvillage)"
      ],
      "metadata": {
        "id": "-oEBvhl7BWCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\" Downloading PlantVillage dataset...\")\n",
        "print(\"Dataset: mohitsingh1804/plantvillage\")\n",
        "print()\n",
        "\n",
        "# Download\n",
        "!kaggle datasets download -d mohitsingh1804/plantvillage\n",
        "\n",
        "print(\"\\n‚úì Download complete!\")\n",
        "\n",
        "# Check file size\n",
        "!ls -lh plantvillage.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dle9nfRBBcSh",
        "outputId": "14dc552a-0ccf-407c-dae3-4d41c8a43b43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Downloading PlantVillage dataset...\n",
            "Dataset: mohitsingh1804/plantvillage\n",
            "\n",
            "Dataset URL: https://www.kaggle.com/datasets/mohitsingh1804/plantvillage\n",
            "License(s): GPL-2.0\n",
            "Downloading plantvillage.zip to /content\n",
            " 96% 785M/818M [00:04<00:00, 41.0MB/s]\n",
            "100% 818M/818M [00:04<00:00, 197MB/s] \n",
            "\n",
            "‚úì Download complete!\n",
            "-rw-r--r-- 1 root root 818M Aug 20  2021 plantvillage.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üì¶ Extracting dataset...\")\n",
        "\n",
        "# Create directory and extract\n",
        "!mkdir -p /content/plantvillage\n",
        "!unzip -q plantvillage.zip -d /content/plantvillage\n",
        "\n",
        "print(\"‚úì Extraction complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGSfL9G6Bhr7",
        "outputId": "3e9d52be-f5e7-4846-a046-47ce0b024a82"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Extracting dataset...\n",
            "‚úì Extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìÇ Dataset structure:\")\n",
        "!ls -lh /content/plantvillage/PlantVillage\n",
        "\n",
        "print(\"\\nüìÇ Train folder:\")\n",
        "!ls /content/plantvillage/PlantVillage/train | head -10\n",
        "\n",
        "print(\"\\nüìÇ Test folder:\")\n",
        "!ls /content/plantvillage/PlantVillage/val | head -10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Lvto8FBlGy",
        "outputId": "c5e831ea-b979-4fca-a236-6ee35a919f7b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÇ Dataset structure:\n",
            "total 8.0K\n",
            "drwxr-xr-x 40 root root 4.0K Oct 27 08:48 train\n",
            "drwxr-xr-x 40 root root 4.0K Oct 27 08:48 val\n",
            "\n",
            "üìÇ Train folder:\n",
            "Apple___Apple_scab\n",
            "Apple___Black_rot\n",
            "Apple___Cedar_apple_rust\n",
            "Apple___healthy\n",
            "Blueberry___healthy\n",
            "Cherry_(including_sour)___healthy\n",
            "Cherry_(including_sour)___Powdery_mildew\n",
            "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "Corn_(maize)___Common_rust_\n",
            "Corn_(maize)___healthy\n",
            "\n",
            "üìÇ Test folder:\n",
            "Apple___Apple_scab\n",
            "Apple___Black_rot\n",
            "Apple___Cedar_apple_rust\n",
            "Apple___healthy\n",
            "Blueberry___healthy\n",
            "Cherry_(including_sour)___healthy\n",
            "Cherry_(including_sour)___Powdery_mildew\n",
            "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "Corn_(maize)___Common_rust_\n",
            "Corn_(maize)___healthy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration and Visualization Utilities\n",
        "\n",
        "\n",
        "This module provides functions for exploring and visualizing the datasets\n",
        "before training, useful for understanding data characteristics."
      ],
      "metadata": {
        "id": "Mv2ZtpTCBmyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET VERIFICATION SCRIPT\n",
        "\n",
        "To check if your datasets are properly structured and accessible"
      ],
      "metadata": {
        "id": "QKOKgjAnCAAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def verify_dataset_structure(dataset_path, dataset_name):\n",
        "    \"\"\"Verify dataset structure and count images\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"VERIFYING {dataset_name.upper()} DATASET\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    print(f\"Path: {dataset_path}\")\n",
        "    print(f\"Exists: {os.path.exists(dataset_path)}\\n\")\n",
        "\n",
        "    if not os.path.exists(dataset_path):\n",
        "        print(\"‚ùå Dataset path does not exist!\")\n",
        "        return False\n",
        "\n",
        "    # Check top-level structure\n",
        "    print(\"üìÇ Top-level contents:\")\n",
        "    top_level = os.listdir(dataset_path)\n",
        "    for item in top_level:\n",
        "        item_path = os.path.join(dataset_path, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"  üìÅ {item}/\")\n",
        "        else:\n",
        "            print(f\"  üìÑ {item}\")\n",
        "\n",
        "    # Check for train/test folders\n",
        "    has_train = os.path.exists(os.path.join(dataset_path, 'train'))\n",
        "    has_test = os.path.exists(os.path.join(dataset_path, 'test'))\n",
        "    has_val = os.path.exists(os.path.join(dataset_path, 'val'))\n",
        "\n",
        "    print(f\"\\nüìä Structure check:\")\n",
        "    print(f\"  train/ folder: {'‚úì' if has_train else '‚úó'}\")\n",
        "    print(f\"  test/ folder: {'‚úì' if has_test else '‚úó'}\")\n",
        "    print(f\"  val/ folder: {'‚úì' if has_val else '‚úó'}\")\n",
        "\n",
        "    # Count images in each split\n",
        "    total_images = 0\n",
        "    splits_info = {}\n",
        "\n",
        "    for split_name in ['train', 'test', 'val']:\n",
        "        split_path = os.path.join(dataset_path, split_name)\n",
        "        if os.path.exists(split_path):\n",
        "            split_images = 0\n",
        "            classes = []\n",
        "\n",
        "            # Iterate through class folders\n",
        "            for class_name in os.listdir(split_path):\n",
        "                class_path = os.path.join(split_path, class_name)\n",
        "                if os.path.isdir(class_path):\n",
        "                    classes.append(class_name)\n",
        "\n",
        "                    # Count images in this class\n",
        "                    images = [f for f in os.listdir(class_path)\n",
        "                             if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "                    split_images += len(images)\n",
        "\n",
        "            splits_info[split_name] = {\n",
        "                'images': split_images,\n",
        "                'classes': len(classes),\n",
        "                'class_names': sorted(classes)\n",
        "            }\n",
        "            total_images += split_images\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\nüìà Dataset summary:\")\n",
        "    for split_name, info in splits_info.items():\n",
        "        print(f\"\\n  {split_name.upper()}:\")\n",
        "        print(f\"    Images: {info['images']:,}\")\n",
        "        print(f\"    Classes: {info['classes']}\")\n",
        "        print(f\"    Sample classes: {', '.join(info['class_names'][:5])}\")\n",
        "        if len(info['class_names']) > 5:\n",
        "            print(f\"                    (and {len(info['class_names']) - 5} more...)\")\n",
        "\n",
        "    print(f\"\\n  TOTAL IMAGES: {total_images:,}\")\n",
        "\n",
        "    # Test loading a sample image\n",
        "    print(f\"\\nüñºÔ∏è  Testing image loading...\")\n",
        "    for split_name, info in splits_info.items():\n",
        "        if info['images'] > 0:\n",
        "            # Find first image\n",
        "            split_path = os.path.join(dataset_path, split_name)\n",
        "            for class_name in info['class_names']:\n",
        "                class_path = os.path.join(split_path, class_name)\n",
        "                images = [f for f in os.listdir(class_path)\n",
        "                         if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "                if images:\n",
        "                    sample_image = os.path.join(class_path, images[0])\n",
        "                    try:\n",
        "                        img = Image.open(sample_image)\n",
        "                        print(f\"  ‚úì Successfully loaded sample from {split_name}/{class_name}\")\n",
        "                        print(f\"    Size: {img.size}, Mode: {img.mode}\")\n",
        "                        break\n",
        "                    except Exception as e:\n",
        "                        print(f\"  ‚úó Error loading {sample_image}: {e}\")\n",
        "            break\n",
        "\n",
        "    if total_images == 0:\n",
        "        print(\"\\n‚ùå No images found! Check your dataset structure.\")\n",
        "        return False\n",
        "    else:\n",
        "        print(f\"\\n‚úì Dataset verification successful!\")\n",
        "        return True\n",
        "\n",
        "\n",
        "def verify_both_datasets(plantvillage_path, plantdoc_path):\n",
        "    \"\"\"Verify both datasets\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DATASET VERIFICATION\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Verify PlantVillage\n",
        "    pv_ok = verify_dataset_structure(plantvillage_path, \"PlantVillage\")\n",
        "\n",
        "    # Verify PlantDoc\n",
        "    pd_ok = verify_dataset_structure(plantdoc_path, \"PlantDoc\")\n",
        "\n",
        "    # Final summary\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VERIFICATION SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"PlantVillage: {'‚úì PASS' if pv_ok else '‚úó FAIL'}\")\n",
        "    print(f\"PlantDoc: {'‚úì PASS' if pd_ok else '‚úó FAIL'}\")\n",
        "\n",
        "    if pv_ok and pd_ok:\n",
        "        print(\"\\nüéâ Both datasets verified successfully!\")\n",
        "        print(\"You can now proceed with training.\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è  Dataset issues detected. Please fix before training.\")\n",
        "\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    return pv_ok and pd_ok\n",
        "\n",
        "\n",
        "# Run verification\n",
        "if __name__ == \"__main__\":\n",
        "    # Set your paths here\n",
        "    PLANTVILLAGE_PATH = '/content/plantvillage/PlantVillage'\n",
        "    PLANTDOC_PATH = '/content/plantdoc'\n",
        "\n",
        "    # Run verification\n",
        "    verify_both_datasets(PLANTVILLAGE_PATH, PLANTDOC_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZkIVc0KCDf7",
        "outputId": "fa549389-18b6-4283-c2ce-e398637f8fb8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATASET VERIFICATION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "VERIFYING PLANTVILLAGE DATASET\n",
            "======================================================================\n",
            "\n",
            "Path: /content/plantvillage/PlantVillage\n",
            "Exists: True\n",
            "\n",
            "üìÇ Top-level contents:\n",
            "  üìÅ val/\n",
            "  üìÅ train/\n",
            "\n",
            "üìä Structure check:\n",
            "  train/ folder: ‚úì\n",
            "  test/ folder: ‚úó\n",
            "  val/ folder: ‚úì\n",
            "\n",
            "üìà Dataset summary:\n",
            "\n",
            "  TRAIN:\n",
            "    Images: 43,444\n",
            "    Classes: 38\n",
            "    Sample classes: Apple___Apple_scab, Apple___Black_rot, Apple___Cedar_apple_rust, Apple___healthy, Blueberry___healthy\n",
            "                    (and 33 more...)\n",
            "\n",
            "  VAL:\n",
            "    Images: 10,861\n",
            "    Classes: 38\n",
            "    Sample classes: Apple___Apple_scab, Apple___Black_rot, Apple___Cedar_apple_rust, Apple___healthy, Blueberry___healthy\n",
            "                    (and 33 more...)\n",
            "\n",
            "  TOTAL IMAGES: 54,305\n",
            "\n",
            "üñºÔ∏è  Testing image loading...\n",
            "  ‚úì Successfully loaded sample from train/Apple___Apple_scab\n",
            "    Size: (256, 256), Mode: RGB\n",
            "\n",
            "‚úì Dataset verification successful!\n",
            "\n",
            "======================================================================\n",
            "VERIFYING PLANTDOC DATASET\n",
            "======================================================================\n",
            "\n",
            "Path: /content/plantdoc\n",
            "Exists: True\n",
            "\n",
            "üìÇ Top-level contents:\n",
            "  üìÑ folder_renamer.py\n",
            "  üìÅ test/\n",
            "  üìÑ file_renamer.py\n",
            "  üìÅ train/\n",
            "\n",
            "üìä Structure check:\n",
            "  train/ folder: ‚úì\n",
            "  test/ folder: ‚úì\n",
            "  val/ folder: ‚úó\n",
            "\n",
            "üìà Dataset summary:\n",
            "\n",
            "  TRAIN:\n",
            "    Images: 2,670\n",
            "    Classes: 28\n",
            "    Sample classes: Apple_Scab_Leaf, Apple_leaf, Apple_rust_leaf, Bell_pepper_leaf, Bell_pepper_leaf_spot\n",
            "                    (and 23 more...)\n",
            "\n",
            "  TEST:\n",
            "    Images: 252\n",
            "    Classes: 27\n",
            "    Sample classes: Apple_Scab_Leaf, Apple_leaf, Apple_rust_leaf, Bell_pepper_leaf, Bell_pepper_leaf_spot\n",
            "                    (and 22 more...)\n",
            "\n",
            "  TOTAL IMAGES: 2,922\n",
            "\n",
            "üñºÔ∏è  Testing image loading...\n",
            "  ‚úì Successfully loaded sample from train/Apple_Scab_Leaf\n",
            "    Size: (504, 330), Mode: RGB\n",
            "\n",
            "‚úì Dataset verification successful!\n",
            "\n",
            "======================================================================\n",
            "VERIFICATION SUMMARY\n",
            "======================================================================\n",
            "PlantVillage: ‚úì PASS\n",
            "PlantDoc: ‚úì PASS\n",
            "\n",
            "üéâ Both datasets verified successfully!\n",
            "You can now proceed with training.\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMPLETE DATA EXPLORATION"
      ],
      "metadata": {
        "id": "H3_BdAyUCKlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================\n",
        "# COMPLETE DATA EXPLORATION - COPY THIS ENTIRE CELL\n",
        "# ===================================================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def analyze_and_visualize(plantvillage_path, plantdoc_path, save_dir='./exploration_results'):\n",
        "    \"\"\"Complete dataset analysis - works with your exact folder structure\"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DATASET EXPLORATION\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # ========================\n",
        "    # ANALYZE PLANTVILLAGE\n",
        "    # ========================\n",
        "    print(\"Analyzing PlantVillage...\")\n",
        "    pv_stats = {'total_images': 0, 'splits': {}}\n",
        "\n",
        "    for split in ['train', 'val']:\n",
        "        split_path = os.path.join(plantvillage_path, split)\n",
        "        if not os.path.exists(split_path):\n",
        "            continue\n",
        "\n",
        "        split_images = 0\n",
        "        split_classes = []\n",
        "        class_counts = {}\n",
        "\n",
        "        for class_name in os.listdir(split_path):\n",
        "            class_path = os.path.join(split_path, class_name)\n",
        "            if not os.path.isdir(class_path):\n",
        "                continue\n",
        "\n",
        "            split_classes.append(class_name)\n",
        "            images = [f for f in os.listdir(class_path)\n",
        "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "            count = len(images)\n",
        "            split_images += count\n",
        "            class_counts[class_name] = count\n",
        "\n",
        "        pv_stats['splits'][split] = {\n",
        "            'images': split_images,\n",
        "            'classes': len(split_classes),\n",
        "            'class_names': sorted(split_classes),\n",
        "            'class_counts': class_counts\n",
        "        }\n",
        "        pv_stats['total_images'] += split_images\n",
        "        print(f\"  {split}: {split_images:,} images, {len(split_classes)} classes\")\n",
        "\n",
        "    # ========================\n",
        "    # ANALYZE PLANTDOC\n",
        "    # ========================\n",
        "    print(\"\\nAnalyzing PlantDoc...\")\n",
        "    pd_stats = {'total_images': 0, 'splits': {}}\n",
        "\n",
        "    for split in ['train', 'test']:\n",
        "        split_path = os.path.join(plantdoc_path, split)\n",
        "        if not os.path.exists(split_path):\n",
        "            continue\n",
        "\n",
        "        split_images = 0\n",
        "        split_classes = []\n",
        "        class_counts = {}\n",
        "\n",
        "        for class_name in os.listdir(split_path):\n",
        "            class_path = os.path.join(split_path, class_name)\n",
        "            if not os.path.isdir(class_path):\n",
        "                continue\n",
        "\n",
        "            split_classes.append(class_name)\n",
        "            images = [f for f in os.listdir(class_path)\n",
        "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "            count = len(images)\n",
        "            split_images += count\n",
        "            class_counts[class_name] = count\n",
        "\n",
        "        pd_stats['splits'][split] = {\n",
        "            'images': split_images,\n",
        "            'classes': len(split_classes),\n",
        "            'class_names': sorted(split_classes),\n",
        "            'class_counts': class_counts\n",
        "        }\n",
        "        pd_stats['total_images'] += split_images\n",
        "        print(f\"  {split}: {split_images:,} images, {len(split_classes)} classes\")\n",
        "\n",
        "    # ========================\n",
        "    # SUMMARY\n",
        "    # ========================\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"SUMMARY\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"PlantVillage total: {pv_stats['total_images']:,} images\")\n",
        "    print(f\"PlantDoc total: {pd_stats['total_images']:,} images\")\n",
        "\n",
        "    # ========================\n",
        "    # VISUALIZATIONS\n",
        "    # ========================\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"GENERATING VISUALIZATIONS\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # 1. Dataset comparison\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    datasets = ['PlantVillage', 'PlantDoc']\n",
        "    totals = [pv_stats['total_images'], pd_stats['total_images']]\n",
        "\n",
        "    bars = axes[0].bar(datasets, totals, color=['skyblue', 'lightcoral'],\n",
        "                       edgecolor='black', alpha=0.8, width=0.6)\n",
        "    axes[0].set_ylabel('Number of Images', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_title('Total Images Comparison', fontsize=14, fontweight='bold')\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    for bar, val in zip(bars, totals):\n",
        "        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(totals)*0.02,\n",
        "                    f'{val:,}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "    pv_train_classes = pv_stats['splits'].get('train', {}).get('classes', 0)\n",
        "    pd_train_classes = pd_stats['splits'].get('train', {}).get('classes', 0)\n",
        "    classes = [pv_train_classes, pd_train_classes]\n",
        "\n",
        "    bars = axes[1].bar(datasets, classes, color=['skyblue', 'lightcoral'],\n",
        "                       edgecolor='black', alpha=0.8, width=0.6)\n",
        "    axes[1].set_ylabel('Number of Classes', fontsize=12, fontweight='bold')\n",
        "    axes[1].set_title('Number of Classes', fontsize=14, fontweight='bold')\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    for bar, val in zip(bars, classes):\n",
        "        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(classes)*0.02,\n",
        "                    f'{val}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_dir, 'dataset_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "    print(\"‚úì Dataset comparison saved\")\n",
        "    plt.close()\n",
        "\n",
        "    # 2. PlantVillage class distribution\n",
        "    if 'train' in pv_stats['splits']:\n",
        "        class_counts = pv_stats['splits']['train']['class_counts']\n",
        "        sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "\n",
        "        plt.figure(figsize=(16, 6))\n",
        "        classes = [c[0] for c in sorted_classes]\n",
        "        counts = [c[1] for c in sorted_classes]\n",
        "\n",
        "        bars = plt.bar(range(len(classes)), counts, color='skyblue',\n",
        "                      edgecolor='black', alpha=0.8)\n",
        "        plt.xlabel('Class', fontsize=12, fontweight='bold')\n",
        "        plt.ylabel('Number of Images', fontsize=12, fontweight='bold')\n",
        "        plt.title('PlantVillage - Top 20 Classes', fontsize=14, fontweight='bold')\n",
        "        plt.xticks(range(len(classes)), classes, rotation=45, ha='right', fontsize=9)\n",
        "        plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "        for bar, count in zip(bars, counts):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts)*0.01,\n",
        "                    f'{count}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, 'plantvillage_classes.png'), dpi=300, bbox_inches='tight')\n",
        "        print(\"‚úì PlantVillage class distribution saved\")\n",
        "        plt.close()\n",
        "\n",
        "    # 3. PlantDoc class distribution\n",
        "    if 'train' in pd_stats['splits']:\n",
        "        class_counts = pd_stats['splits']['train']['class_counts']\n",
        "        sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        plt.figure(figsize=(16, 6))\n",
        "        classes = [c[0] for c in sorted_classes]\n",
        "        counts = [c[1] for c in sorted_classes]\n",
        "\n",
        "        bars = plt.bar(range(len(classes)), counts, color='lightcoral',\n",
        "                      edgecolor='black', alpha=0.8)\n",
        "        plt.xlabel('Class', fontsize=12, fontweight='bold')\n",
        "        plt.ylabel('Number of Images', fontsize=12, fontweight='bold')\n",
        "        plt.title('PlantDoc - Class Distribution', fontsize=14, fontweight='bold')\n",
        "        plt.xticks(range(len(classes)), classes, rotation=45, ha='right', fontsize=9)\n",
        "        plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "        for bar, count in zip(bars, counts):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts)*0.01,\n",
        "                    f'{count}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, 'plantdoc_classes.png'), dpi=300, bbox_inches='tight')\n",
        "        print(\"‚úì PlantDoc class distribution saved\")\n",
        "        plt.close()\n",
        "\n",
        "    # 4. Sample images from PlantVillage\n",
        "    pv_train_path = os.path.join(plantvillage_path, 'train')\n",
        "    if os.path.exists(pv_train_path):\n",
        "        classes = [d for d in os.listdir(pv_train_path)\n",
        "                  if os.path.isdir(os.path.join(pv_train_path, d))][:16]\n",
        "\n",
        "        fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for idx, class_name in enumerate(classes):\n",
        "            class_path = os.path.join(pv_train_path, class_name)\n",
        "            images = [f for f in os.listdir(class_path)\n",
        "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "            if images:\n",
        "                img_path = os.path.join(class_path, images[0])\n",
        "                try:\n",
        "                    img = Image.open(img_path)\n",
        "                    axes[idx].imshow(img)\n",
        "                    axes[idx].set_title(class_name, fontsize=8, fontweight='bold')\n",
        "                    axes[idx].axis('off')\n",
        "                except:\n",
        "                    axes[idx].axis('off')\n",
        "\n",
        "        for idx in range(len(classes), 16):\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "        plt.suptitle('PlantVillage - Sample Images', fontsize=16, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, 'plantvillage_samples.png'), dpi=300, bbox_inches='tight')\n",
        "        print(\"‚úì PlantVillage samples saved\")\n",
        "        plt.close()\n",
        "\n",
        "    # 5. Sample images from PlantDoc\n",
        "    pd_train_path = os.path.join(plantdoc_path, 'train')\n",
        "    if os.path.exists(pd_train_path):\n",
        "        classes = [d for d in os.listdir(pd_train_path)\n",
        "                  if os.path.isdir(os.path.join(pd_train_path, d))][:16]\n",
        "\n",
        "        fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for idx, class_name in enumerate(classes):\n",
        "            class_path = os.path.join(pd_train_path, class_name)\n",
        "            images = [f for f in os.listdir(class_path)\n",
        "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "            if images:\n",
        "                img_path = os.path.join(class_path, images[0])\n",
        "                try:\n",
        "                    img = Image.open(img_path)\n",
        "                    axes[idx].imshow(img)\n",
        "                    axes[idx].set_title(class_name, fontsize=8, fontweight='bold')\n",
        "                    axes[idx].axis('off')\n",
        "                except:\n",
        "                    axes[idx].axis('off')\n",
        "\n",
        "        for idx in range(len(classes), 16):\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "        plt.suptitle('PlantDoc - Sample Images', fontsize=16, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, 'plantdoc_samples.png'), dpi=300, bbox_inches='tight')\n",
        "        print(\"‚úì PlantDoc samples saved\")\n",
        "        plt.close()\n",
        "\n",
        "    print(f\"\\n‚úì All visualizations saved to {save_dir}/\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    return pv_stats, pd_stats\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# RUN THE EXPLORATION\n",
        "# ===================================================================\n",
        "PLANTVILLAGE_PATH = '/content/plantvillage/PlantVillage'\n",
        "PLANTDOC_PATH = '/content/plantdoc'\n",
        "\n",
        "pv_stats, pd_stats = analyze_and_visualize(PLANTVILLAGE_PATH, PLANTDOC_PATH)\n",
        "\n",
        "print(\"‚úì EXPLORATION COMPLETE!\")\n",
        "print(f\"\\nPlantVillage: {pv_stats['total_images']:,} images\")\n",
        "print(f\"PlantDoc: {pd_stats['total_images']:,} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afVVHaTKCSTU",
        "outputId": "01132434-201d-4bf1-ca31-0e289092b351"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATASET EXPLORATION\n",
            "======================================================================\n",
            "\n",
            "Analyzing PlantVillage...\n",
            "  train: 43,444 images, 38 classes\n",
            "  val: 10,861 images, 38 classes\n",
            "\n",
            "Analyzing PlantDoc...\n",
            "  train: 2,670 images, 28 classes\n",
            "  test: 252 images, 27 classes\n",
            "\n",
            "======================================================================\n",
            "SUMMARY\n",
            "======================================================================\n",
            "PlantVillage total: 54,305 images\n",
            "PlantDoc total: 2,922 images\n",
            "\n",
            "======================================================================\n",
            "GENERATING VISUALIZATIONS\n",
            "======================================================================\n",
            "\n",
            "‚úì Dataset comparison saved\n",
            "‚úì PlantVillage class distribution saved\n",
            "‚úì PlantDoc class distribution saved\n",
            "‚úì PlantVillage samples saved\n",
            "‚úì PlantDoc samples saved\n",
            "\n",
            "‚úì All visualizations saved to ./exploration_results/\n",
            "======================================================================\n",
            "\n",
            "‚úì EXPLORATION COMPLETE!\n",
            "\n",
            "PlantVillage: 54,305 images\n",
            "PlantDoc: 2,922 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODULE 1: Data Loading and Pre-Processing Pipeline Implementation\n",
        "\n",
        "This module handles data loading, preprocessing, and augmentation for both\n",
        "PlantVillage (source) and PlantDoc (target) datasets.\n",
        "\n",
        "Figure 1: Data Loading and Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "iai_NHnsCcCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASS MAPPING ANALYSIS TOOL**\n",
        "\n",
        "Analyzes and finds common classes between PlantVillage and PlantDoc"
      ],
      "metadata": {
        "id": "oVmdD7Jhrnqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile class_mapper.py\n",
        "\n",
        "\"\"\"\n",
        "CLASS MAPPING ANALYSIS TOOL\n",
        "Analyzes and finds common classes between PlantVillage and PlantDoc\n",
        "\n",
        "Run this FIRST to see what classes will be used for training\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def normalize_class_name(class_name):\n",
        "    \"\"\"\n",
        "    Normalize class names to find matches\n",
        "    Examples:\n",
        "      'Apple___Apple_scab' -> 'apple scab'\n",
        "      'Apple_Scab_Leaf' -> 'apple scab'\n",
        "    \"\"\"\n",
        "    # Replace underscores with spaces\n",
        "    normalized = class_name.replace('_', ' ').lower()\n",
        "\n",
        "    # Remove common suffixes\n",
        "    suffixes = [' leaf', ' leaves', 'including sour', '(including sour)']\n",
        "    for suffix in suffixes:\n",
        "        normalized = normalized.replace(suffix, '')\n",
        "\n",
        "    # Remove multiple spaces\n",
        "    normalized = ' '.join(normalized.split())\n",
        "\n",
        "    # Remove parentheses\n",
        "    normalized = normalized.replace('(', '').replace(')', '')\n",
        "\n",
        "    return normalized.strip()\n",
        "\n",
        "\n",
        "def extract_disease_keywords(class_name):\n",
        "    \"\"\"Extract key disease terms for matching\"\"\"\n",
        "    name_lower = class_name.lower()\n",
        "\n",
        "    # Disease keywords to look for\n",
        "    diseases = [\n",
        "        'scab', 'rust', 'blight', 'rot', 'spot', 'mildew',\n",
        "        'healthy', 'bacterial', 'fungal', 'leaf', 'early', 'late',\n",
        "        'cercospora', 'gray', 'common', 'northern', 'septoria'\n",
        "    ]\n",
        "\n",
        "    # Plant keywords\n",
        "    plants = [\n",
        "        'apple', 'tomato', 'potato', 'corn', 'grape', 'cherry',\n",
        "        'peach', 'pepper', 'strawberry', 'raspberry', 'blueberry',\n",
        "        'bell pepper', 'maize'\n",
        "    ]\n",
        "\n",
        "    found_diseases = [d for d in diseases if d in name_lower]\n",
        "    found_plants = [p for p in plants if p in name_lower]\n",
        "\n",
        "    return found_plants, found_diseases\n",
        "\n",
        "\n",
        "def analyze_class_overlap(plantvillage_path, plantdoc_path):\n",
        "    \"\"\"\n",
        "    Analyze class overlap between datasets\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with analysis results and class mappings\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CLASS OVERLAP ANALYSIS\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    # Get PlantVillage classes\n",
        "    pv_path = os.path.join(plantvillage_path, 'PlantVillage', 'train') \\\n",
        "              if os.path.exists(os.path.join(plantvillage_path, 'PlantVillage')) \\\n",
        "              else os.path.join(plantvillage_path, 'train')\n",
        "\n",
        "    pv_classes = sorted([d for d in os.listdir(pv_path)\n",
        "                        if os.path.isdir(os.path.join(pv_path, d))])\n",
        "\n",
        "    # Get PlantDoc classes\n",
        "    pd_path = os.path.join(plantdoc_path, 'train')\n",
        "    pd_classes = sorted([d for d in os.listdir(pd_path)\n",
        "                        if os.path.isdir(os.path.join(pd_path, d))])\n",
        "\n",
        "    print(f\"üìä Dataset Statistics:\")\n",
        "    print(f\"   PlantVillage classes: {len(pv_classes)}\")\n",
        "    print(f\"   PlantDoc classes: {len(pd_classes)}\")\n",
        "\n",
        "    # Normalize class names\n",
        "    pv_normalized = {cls: normalize_class_name(cls) for cls in pv_classes}\n",
        "    pd_normalized = {cls: normalize_class_name(cls) for cls in pd_classes}\n",
        "\n",
        "    # Find exact normalized matches\n",
        "    pv_norm_set = set(pv_normalized.values())\n",
        "    pd_norm_set = set(pd_normalized.values())\n",
        "    exact_matches = pv_norm_set & pd_norm_set\n",
        "\n",
        "    print(f\"\\nüîç Exact matches (after normalization): {len(exact_matches)}\")\n",
        "\n",
        "    # Create mapping for exact matches\n",
        "    class_mapping = []\n",
        "\n",
        "    for norm_name in sorted(exact_matches):\n",
        "        # Find original names\n",
        "        pv_original = [k for k, v in pv_normalized.items() if v == norm_name][0]\n",
        "        pd_original = [k for k, v in pd_normalized.items() if v == norm_name][0]\n",
        "\n",
        "        class_mapping.append({\n",
        "            'plantvillage': pv_original,\n",
        "            'plantdoc': pd_original,\n",
        "            'normalized': norm_name\n",
        "        })\n",
        "\n",
        "    # Find fuzzy matches (same plant + disease keywords)\n",
        "    print(f\"\\nüîé Finding additional fuzzy matches...\")\n",
        "\n",
        "    fuzzy_matches = []\n",
        "    for pv_cls in pv_classes:\n",
        "        pv_plants, pv_diseases = extract_disease_keywords(pv_cls)\n",
        "\n",
        "        for pd_cls in pd_classes:\n",
        "            # Skip if already matched\n",
        "            if any(m['plantvillage'] == pv_cls or m['plantdoc'] == pd_cls\n",
        "                   for m in class_mapping):\n",
        "                continue\n",
        "\n",
        "            pd_plants, pd_diseases = extract_disease_keywords(pd_cls)\n",
        "\n",
        "            # Check if same plant and disease\n",
        "            common_plants = set(pv_plants) & set(pd_plants)\n",
        "            common_diseases = set(pv_diseases) & set(pd_diseases)\n",
        "\n",
        "            if common_plants and common_diseases:\n",
        "                fuzzy_matches.append({\n",
        "                    'plantvillage': pv_cls,\n",
        "                    'plantdoc': pd_cls,\n",
        "                    'plants': list(common_plants),\n",
        "                    'diseases': list(common_diseases)\n",
        "                })\n",
        "\n",
        "    print(f\"   Found {len(fuzzy_matches)} potential fuzzy matches\")\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"MATCHED CLASSES ({len(class_mapping)} exact matches)\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    for i, match in enumerate(class_mapping, 1):\n",
        "        print(f\"{i:2d}. PlantVillage: {match['plantvillage']}\")\n",
        "        print(f\"    PlantDoc:     {match['plantdoc']}\")\n",
        "        print(f\"    Normalized:   {match['normalized']}\")\n",
        "        print()\n",
        "\n",
        "    if fuzzy_matches:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"POTENTIAL FUZZY MATCHES ({len(fuzzy_matches)} found)\")\n",
        "        print(f\"{'='*80}\\n\")\n",
        "        print(\"‚ö†Ô∏è  These require manual verification:\")\n",
        "        print()\n",
        "\n",
        "        for i, match in enumerate(fuzzy_matches, 1):\n",
        "            print(f\"{i:2d}. PlantVillage: {match['plantvillage']}\")\n",
        "            print(f\"    PlantDoc:     {match['plantdoc']}\")\n",
        "            print(f\"    Common: {match['plants']} + {match['diseases']}\")\n",
        "            print()\n",
        "\n",
        "    # Summary statistics\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"   Total PlantVillage classes: {len(pv_classes)}\")\n",
        "    print(f\"   Total PlantDoc classes: {len(pd_classes)}\")\n",
        "    print(f\"   Exact matches: {len(class_mapping)}\")\n",
        "    print(f\"   Fuzzy matches: {len(fuzzy_matches)}\")\n",
        "    print(f\"   Recommended classes for training: {len(class_mapping)}\")\n",
        "\n",
        "    # Coverage analysis\n",
        "    if class_mapping:\n",
        "        # Count images in matched classes\n",
        "        pv_matched_images = 0\n",
        "        pd_matched_images = 0\n",
        "\n",
        "        for match in class_mapping:\n",
        "            pv_class_path = os.path.join(pv_path, match['plantvillage'])\n",
        "            pv_images = len([f for f in os.listdir(pv_class_path)\n",
        "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            pv_matched_images += pv_images\n",
        "\n",
        "            pd_class_path = os.path.join(pd_path, match['plantdoc'])\n",
        "            pd_images = len([f for f in os.listdir(pd_class_path)\n",
        "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            pd_matched_images += pd_images\n",
        "\n",
        "        # Total images\n",
        "        pv_total_images = sum(len([f for f in os.listdir(os.path.join(pv_path, cls))\n",
        "                                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "                            for cls in pv_classes)\n",
        "        pd_total_images = sum(len([f for f in os.listdir(os.path.join(pd_path, cls))\n",
        "                                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "                            for cls in pd_classes)\n",
        "\n",
        "        print(f\"\\nüìä Dataset Coverage:\")\n",
        "        print(f\"   PlantVillage: {pv_matched_images:,} / {pv_total_images:,} images \"\n",
        "              f\"({100*pv_matched_images/pv_total_images:.1f}%)\")\n",
        "        print(f\"   PlantDoc: {pd_matched_images:,} / {pd_total_images:,} images \"\n",
        "              f\"({100*pd_matched_images/pd_total_images:.1f}%)\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\\n\")\n",
        "\n",
        "    # Save mapping to file\n",
        "    mapping_data = {\n",
        "        'exact_matches': class_mapping,\n",
        "        'fuzzy_matches': fuzzy_matches,\n",
        "        'num_classes': len(class_mapping),\n",
        "        'plantvillage_total': len(pv_classes),\n",
        "        'plantdoc_total': len(pd_classes)\n",
        "    }\n",
        "\n",
        "    with open('class_mapping.json', 'w') as f:\n",
        "        json.dump(mapping_data, f, indent=2)\n",
        "\n",
        "    print(\"‚úì Class mapping saved to 'class_mapping.json'\")\n",
        "\n",
        "    return mapping_data\n",
        "\n",
        "\n",
        "def create_class_mapping_dict(mapping_data):\n",
        "    \"\"\"\n",
        "    Create dictionaries for easy class mapping during data loading\n",
        "\n",
        "    Returns:\n",
        "        pv_to_common: PlantVillage class name -> common index\n",
        "        pd_to_common: PlantDoc class name -> common index\n",
        "        common_names: List of common class names\n",
        "    \"\"\"\n",
        "    exact_matches = mapping_data['exact_matches']\n",
        "\n",
        "    pv_to_common = {}\n",
        "    pd_to_common = {}\n",
        "    common_names = []\n",
        "\n",
        "    for idx, match in enumerate(exact_matches):\n",
        "        pv_to_common[match['plantvillage']] = idx\n",
        "        pd_to_common[match['plantdoc']] = idx\n",
        "        common_names.append(match['normalized'])\n",
        "\n",
        "    return pv_to_common, pd_to_common, common_names\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Set your paths\n",
        "    PLANTVILLAGE_PATH = '/content/plantvillage'\n",
        "    PLANTDOC_PATH = '/content/plantdoc'\n",
        "\n",
        "    # Run analysis\n",
        "    mapping_data = analyze_class_overlap(PLANTVILLAGE_PATH, PLANTDOC_PATH)\n",
        "\n",
        "    # Create mapping dictionaries\n",
        "    pv_map, pd_map, common_names = create_class_mapping_dict(mapping_data)\n",
        "\n",
        "    print(\"\\nüìã Usage in training:\")\n",
        "    print(f\"   NUM_CLASSES = {len(common_names)}\")\n",
        "    print(f\"   Common classes: {common_names[:5]}...\")\n",
        "\n",
        "    print(\"\\n‚úÖ Ready to proceed with filtered datasets!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIWIw9eTrm_1",
        "outputId": "1789ec1b-0b92-4bc3-fd7f-efaf43c9e082"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing class_mapper.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run it\n",
        "exec(open('class_mapper.py').read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6BUjJHz_sLn8",
        "outputId": "32cb5c8f-d893-41e9-9267-d5815d6c2074"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CLASS OVERLAP ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "üìä Dataset Statistics:\n",
            "   PlantVillage classes: 38\n",
            "   PlantDoc classes: 28\n",
            "\n",
            "üîç Exact matches (after normalization): 9\n",
            "\n",
            "üîé Finding additional fuzzy matches...\n",
            "   Found 18 potential fuzzy matches\n",
            "\n",
            "================================================================================\n",
            "MATCHED CLASSES (9 exact matches)\n",
            "================================================================================\n",
            "\n",
            " 1. PlantVillage: Grape___Black_rot\n",
            "    PlantDoc:     grape_leaf_black_rot\n",
            "    Normalized:   grape black rot\n",
            "\n",
            " 2. PlantVillage: Potato___Early_blight\n",
            "    PlantDoc:     Potato_leaf_early_blight\n",
            "    Normalized:   potato early blight\n",
            "\n",
            " 3. PlantVillage: Potato___Late_blight\n",
            "    PlantDoc:     Potato_leaf_late_blight\n",
            "    Normalized:   potato late blight\n",
            "\n",
            " 4. PlantVillage: Squash___Powdery_mildew\n",
            "    PlantDoc:     Squash_Powdery_mildew_leaf\n",
            "    Normalized:   squash powdery mildew\n",
            "\n",
            " 5. PlantVillage: Tomato___Bacterial_spot\n",
            "    PlantDoc:     Tomato_leaf_bacterial_spot\n",
            "    Normalized:   tomato bacterial spot\n",
            "\n",
            " 6. PlantVillage: Tomato___Early_blight\n",
            "    PlantDoc:     Tomato_Early_blight_leaf\n",
            "    Normalized:   tomato early blight\n",
            "\n",
            " 7. PlantVillage: Tomato___Late_blight\n",
            "    PlantDoc:     Tomato_leaf_late_blight\n",
            "    Normalized:   tomato late blight\n",
            "\n",
            " 8. PlantVillage: Tomato___Leaf_Mold\n",
            "    PlantDoc:     Tomato_mold_leaf\n",
            "    Normalized:   tomato mold\n",
            "\n",
            " 9. PlantVillage: Tomato___Septoria_leaf_spot\n",
            "    PlantDoc:     Tomato_Septoria_leaf_spot\n",
            "    Normalized:   tomato septoria spot\n",
            "\n",
            "\n",
            "================================================================================\n",
            "POTENTIAL FUZZY MATCHES (18 found)\n",
            "================================================================================\n",
            "\n",
            "‚ö†Ô∏è  These require manual verification:\n",
            "\n",
            " 1. PlantVillage: Apple___Apple_scab\n",
            "    PlantDoc:     Apple_Scab_Leaf\n",
            "    Common: ['apple'] + ['scab']\n",
            "\n",
            " 2. PlantVillage: Apple___Cedar_apple_rust\n",
            "    PlantDoc:     Apple_rust_leaf\n",
            "    Common: ['apple'] + ['rust']\n",
            "\n",
            " 3. PlantVillage: Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "    PlantDoc:     Corn_Gray_leaf_spot\n",
            "    Common: ['corn'] + ['leaf', 'spot', 'gray']\n",
            "\n",
            " 4. PlantVillage: Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "    PlantDoc:     Corn_leaf_blight\n",
            "    Common: ['corn'] + ['leaf']\n",
            "\n",
            " 5. PlantVillage: Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "    PlantDoc:     Corn_rust_leaf\n",
            "    Common: ['corn'] + ['leaf']\n",
            "\n",
            " 6. PlantVillage: Corn_(maize)___Common_rust_\n",
            "    PlantDoc:     Corn_rust_leaf\n",
            "    Common: ['corn'] + ['rust']\n",
            "\n",
            " 7. PlantVillage: Corn_(maize)___Northern_Leaf_Blight\n",
            "    PlantDoc:     Corn_Gray_leaf_spot\n",
            "    Common: ['corn'] + ['leaf']\n",
            "\n",
            " 8. PlantVillage: Corn_(maize)___Northern_Leaf_Blight\n",
            "    PlantDoc:     Corn_leaf_blight\n",
            "    Common: ['corn'] + ['leaf', 'blight']\n",
            "\n",
            " 9. PlantVillage: Corn_(maize)___Northern_Leaf_Blight\n",
            "    PlantDoc:     Corn_rust_leaf\n",
            "    Common: ['corn'] + ['leaf']\n",
            "\n",
            "10. PlantVillage: Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
            "    PlantDoc:     grape_leaf\n",
            "    Common: ['grape'] + ['leaf']\n",
            "\n",
            "11. PlantVillage: Pepper,_bell___Bacterial_spot\n",
            "    PlantDoc:     Bell_pepper_leaf_spot\n",
            "    Common: ['pepper'] + ['spot']\n",
            "\n",
            "12. PlantVillage: Strawberry___Leaf_scorch\n",
            "    PlantDoc:     Strawberry_leaf\n",
            "    Common: ['strawberry'] + ['leaf']\n",
            "\n",
            "13. PlantVillage: Tomato___Spider_mites Two-spotted_spider_mite\n",
            "    PlantDoc:     Tomato_two_spotted_spider_mites_leaf\n",
            "    Common: ['tomato'] + ['spot']\n",
            "\n",
            "14. PlantVillage: Tomato___Target_Spot\n",
            "    PlantDoc:     Tomato_two_spotted_spider_mites_leaf\n",
            "    Common: ['tomato'] + ['spot']\n",
            "\n",
            "15. PlantVillage: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "    PlantDoc:     Tomato_leaf\n",
            "    Common: ['tomato'] + ['leaf']\n",
            "\n",
            "16. PlantVillage: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "    PlantDoc:     Tomato_leaf_mosaic_virus\n",
            "    Common: ['tomato'] + ['leaf']\n",
            "\n",
            "17. PlantVillage: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "    PlantDoc:     Tomato_leaf_yellow_virus\n",
            "    Common: ['tomato'] + ['leaf']\n",
            "\n",
            "18. PlantVillage: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "    PlantDoc:     Tomato_two_spotted_spider_mites_leaf\n",
            "    Common: ['tomato'] + ['leaf']\n",
            "\n",
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "   Total PlantVillage classes: 38\n",
            "   Total PlantDoc classes: 28\n",
            "   Exact matches: 9\n",
            "   Fuzzy matches: 18\n",
            "   Recommended classes for training: 9\n",
            "\n",
            "üìä Dataset Coverage:\n",
            "   PlantVillage: 10,219 / 43,444 images (23.5%)\n",
            "   PlantDoc: 1,063 / 2,670 images (39.8%)\n",
            "\n",
            "================================================================================\n",
            "\n",
            "‚úì Class mapping saved to 'class_mapping.json'\n",
            "\n",
            "üìã Usage in training:\n",
            "   NUM_CLASSES = 9\n",
            "   Common classes: ['grape black rot', 'potato early blight', 'potato late blight', 'squash powdery mildew', 'tomato bacterial spot']...\n",
            "\n",
            "‚úÖ Ready to proceed with filtered datasets!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_preprocessing.py\n",
        "\n",
        "\"\"\"\n",
        "MODULE 1: DATA PREPROCESSING (WITH COMMON CLASS FILTERING)\n",
        "Filters datasets to only use classes that exist in both PlantVillage and PlantDoc\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "\n",
        "def load_class_mapping(mapping_file='class_mapping.json'):\n",
        "    \"\"\"Load class mapping from JSON file\"\"\"\n",
        "    if not os.path.exists(mapping_file):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Class mapping file not found: {mapping_file}\\n\"\n",
        "            f\"Please run class_mapper.py first to generate the mapping!\"\n",
        "        )\n",
        "\n",
        "    with open(mapping_file, 'r') as f:\n",
        "        mapping_data = json.load(f)\n",
        "\n",
        "    # Create mapping dictionaries\n",
        "    pv_to_common = {}\n",
        "    pd_to_common = {}\n",
        "    common_names = []\n",
        "\n",
        "    for idx, match in enumerate(mapping_data['exact_matches']):\n",
        "        pv_to_common[match['plantvillage']] = idx\n",
        "        pd_to_common[match['plantdoc']] = idx\n",
        "        common_names.append(match['normalized'])\n",
        "\n",
        "    return pv_to_common, pd_to_common, common_names, mapping_data\n",
        "\n",
        "\n",
        "class PlantVillageDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for PlantVillage (Source Domain) - Filtered to common classes\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, split='train', transform=None, class_filter=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir: Root directory containing PlantVillage dataset\n",
        "            split: 'train', 'val', or 'test'\n",
        "            transform: Optional transform to be applied on images\n",
        "            class_filter: Dictionary mapping class names to indices (only use these classes)\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.class_filter = class_filter\n",
        "\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.class_names = []\n",
        "\n",
        "        # Handle nested PlantVillage folder\n",
        "        if os.path.exists(os.path.join(root_dir, 'PlantVillage')):\n",
        "            root_dir = os.path.join(root_dir, 'PlantVillage')\n",
        "\n",
        "        # Determine data directory\n",
        "        if split == 'train':\n",
        "            data_dir = os.path.join(root_dir, 'train')\n",
        "        elif split == 'val':\n",
        "            data_dir = os.path.join(root_dir, 'val')\n",
        "        else:  # test\n",
        "            data_dir = os.path.join(root_dir, 'val')\n",
        "\n",
        "        if not os.path.exists(data_dir):\n",
        "            raise FileNotFoundError(f\"Directory not found: {data_dir}\")\n",
        "\n",
        "        # Get all class folders\n",
        "        all_classes = sorted([d for d in os.listdir(data_dir)\n",
        "                             if os.path.isdir(os.path.join(data_dir, d))])\n",
        "\n",
        "        # Filter to common classes if specified\n",
        "        if class_filter is not None:\n",
        "            classes_to_use = [c for c in all_classes if c in class_filter]\n",
        "            print(f\"  Filtering from {len(all_classes)} to {len(classes_to_use)} common classes\")\n",
        "        else:\n",
        "            classes_to_use = all_classes\n",
        "\n",
        "        # Load images from filtered classes\n",
        "        for class_name in classes_to_use:\n",
        "            class_path = os.path.join(data_dir, class_name)\n",
        "\n",
        "            # Get mapped index\n",
        "            if class_filter is not None:\n",
        "                class_idx = class_filter[class_name]\n",
        "            else:\n",
        "                class_idx = len(self.class_names)\n",
        "\n",
        "            if class_name not in [c for c, _ in self.class_names]:\n",
        "                self.class_names.append((class_name, class_idx))\n",
        "\n",
        "            # Get all images\n",
        "            images = [f for f in os.listdir(class_path)\n",
        "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "            # Split for test\n",
        "            if split == 'test':\n",
        "                np.random.seed(42)\n",
        "                np.random.shuffle(images)\n",
        "                mid = len(images) // 2\n",
        "                images = images[mid:]\n",
        "            elif split == 'val':\n",
        "                np.random.seed(42)\n",
        "                np.random.shuffle(images)\n",
        "                mid = len(images) // 2\n",
        "                images = images[:mid]\n",
        "\n",
        "            for img_name in images:\n",
        "                self.image_paths.append(os.path.join(class_path, img_name))\n",
        "                self.labels.append(class_idx)\n",
        "\n",
        "        print(f\"  Loaded {len(self.image_paths)} images from {len(set(self.labels))} classes\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label, 'source'\n",
        "\n",
        "\n",
        "class PlantDocDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for PlantDoc (Target Domain) - Filtered to common classes\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, split='train', transform=None, labeled=True, class_filter=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir: Root directory containing PlantDoc dataset\n",
        "            split: 'train', 'val', or 'test'\n",
        "            transform: Optional transform to be applied on images\n",
        "            labeled: Whether to return labels\n",
        "            class_filter: Dictionary mapping class names to indices\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.labeled = labeled\n",
        "        self.class_filter = class_filter\n",
        "\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.class_names = []\n",
        "\n",
        "        # Determine data directory\n",
        "        if split == 'train':\n",
        "            data_dir = os.path.join(root_dir, 'train')\n",
        "        else:\n",
        "            data_dir = os.path.join(root_dir, 'test')\n",
        "\n",
        "        if not os.path.exists(data_dir):\n",
        "            raise FileNotFoundError(f\"Directory not found: {data_dir}\")\n",
        "\n",
        "        # Get all class folders\n",
        "        all_classes = sorted([d for d in os.listdir(data_dir)\n",
        "                             if os.path.isdir(os.path.join(data_dir, d))])\n",
        "\n",
        "        # Filter to common classes\n",
        "        if class_filter is not None:\n",
        "            classes_to_use = [c for c in all_classes if c in class_filter]\n",
        "            print(f\"  Filtering from {len(all_classes)} to {len(classes_to_use)} common classes\")\n",
        "        else:\n",
        "            classes_to_use = all_classes\n",
        "\n",
        "        # Collect all images\n",
        "        all_images = []\n",
        "\n",
        "        for class_name in classes_to_use:\n",
        "            class_path = os.path.join(data_dir, class_name)\n",
        "\n",
        "            # Get mapped index\n",
        "            if class_filter is not None:\n",
        "                class_idx = class_filter[class_name]\n",
        "            else:\n",
        "                class_idx = len(self.class_names)\n",
        "\n",
        "            if class_name not in self.class_names:\n",
        "                self.class_names.append(class_name)\n",
        "\n",
        "            # Get all images\n",
        "            images = [f for f in os.listdir(class_path)\n",
        "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "            for img_name in images:\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "                all_images.append((img_path, class_idx))\n",
        "\n",
        "        # Split for val/test\n",
        "        if split in ['val', 'test']:\n",
        "            np.random.seed(42)\n",
        "            np.random.shuffle(all_images)\n",
        "            mid = len(all_images) // 2\n",
        "            if split == 'val':\n",
        "                all_images = all_images[:mid]\n",
        "            else:\n",
        "                all_images = all_images[mid:]\n",
        "\n",
        "        # Store\n",
        "        for img_path, label in all_images:\n",
        "            self.image_paths.append(img_path)\n",
        "            self.labels.append(label)\n",
        "\n",
        "        print(f\"  Loaded {len(self.image_paths)} images from {len(set(self.labels))} classes\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        label = self.labels[idx] if self.labeled else -1\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label, 'target'\n",
        "\n",
        "\n",
        "def get_transforms(split='train', augment=True):\n",
        "    \"\"\"Get appropriate transforms\"\"\"\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "\n",
        "    if split == 'train' and augment:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomRotation(degrees=20),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1),\n",
        "            transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.3),\n",
        "            transforms.ToTensor(),\n",
        "            normalize\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            normalize\n",
        "        ])\n",
        "\n",
        "\n",
        "def create_data_loaders(plantvillage_path, plantdoc_path, batch_size=32,\n",
        "                       use_common_classes=True, mapping_file='class_mapping.json'):\n",
        "    \"\"\"\n",
        "    Create data loaders with optional common class filtering\n",
        "\n",
        "    Args:\n",
        "        plantvillage_path: Path to PlantVillage\n",
        "        plantdoc_path: Path to PlantDoc\n",
        "        batch_size: Batch size\n",
        "        use_common_classes: If True, filter to common classes only\n",
        "        mapping_file: Path to class mapping JSON file\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of data loaders and mapping info\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CREATING FILTERED DATASETS (COMMON CLASSES ONLY)\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # Load class mapping\n",
        "    if use_common_classes:\n",
        "        print(\"üìã Loading class mapping...\")\n",
        "        pv_class_map, pd_class_map, common_names, mapping_data = load_class_mapping(mapping_file)\n",
        "        num_classes = len(common_names)\n",
        "        print(f\"   Using {num_classes} common classes\")\n",
        "        print(f\"   Classes: {', '.join(common_names[:5])}{'...' if len(common_names) > 5 else ''}\\n\")\n",
        "    else:\n",
        "        pv_class_map = None\n",
        "        pd_class_map = None\n",
        "        common_names = None\n",
        "        num_classes = None\n",
        "\n",
        "    # Create datasets\n",
        "    print(\"üìÇ Loading PlantVillage (Source Domain)...\")\n",
        "    source_train = PlantVillageDataset(\n",
        "        plantvillage_path, 'train', get_transforms('train', True), pv_class_map\n",
        "    )\n",
        "    source_val = PlantVillageDataset(\n",
        "        plantvillage_path, 'val', get_transforms('val'), pv_class_map\n",
        "    )\n",
        "    source_test = PlantVillageDataset(\n",
        "        plantvillage_path, 'test', get_transforms('test'), pv_class_map\n",
        "    )\n",
        "\n",
        "    print(\"\\nüìÇ Loading PlantDoc (Target Domain)...\")\n",
        "    target_train = PlantDocDataset(\n",
        "        plantdoc_path, 'train', get_transforms('train', True), False, pd_class_map\n",
        "    )\n",
        "    target_val = PlantDocDataset(\n",
        "        plantdoc_path, 'val', get_transforms('val'), True, pd_class_map\n",
        "    )\n",
        "    target_test = PlantDocDataset(\n",
        "        plantdoc_path, 'test', get_transforms('test'), True, pd_class_map\n",
        "    )\n",
        "\n",
        "    # Create loaders\n",
        "    loaders = {\n",
        "        'source_train': DataLoader(source_train, batch_size=batch_size, shuffle=True,\n",
        "                                   num_workers=2, pin_memory=True, drop_last=True),\n",
        "        'source_val': DataLoader(source_val, batch_size=batch_size, shuffle=False,\n",
        "                                num_workers=2, pin_memory=True),\n",
        "        'source_test': DataLoader(source_test, batch_size=batch_size, shuffle=False,\n",
        "                                 num_workers=2, pin_memory=True),\n",
        "        'target_train': DataLoader(target_train, batch_size=batch_size//2, shuffle=True,\n",
        "                                   num_workers=2, pin_memory=True, drop_last=True),\n",
        "        'target_val': DataLoader(target_val, batch_size=batch_size, shuffle=False,\n",
        "                                num_workers=2, pin_memory=True),\n",
        "        'target_test': DataLoader(target_test, batch_size=batch_size, shuffle=False,\n",
        "                                 num_workers=2, pin_memory=True)\n",
        "    }\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DATASET SUMMARY (FILTERED TO COMMON CLASSES)\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nüìä Common Classes: {num_classes}\")\n",
        "    print(f\"\\n   Source Domain (PlantVillage):\")\n",
        "    print(f\"      Train: {len(source_train):>6,} images\")\n",
        "    print(f\"      Val:   {len(source_val):>6,} images\")\n",
        "    print(f\"      Test:  {len(source_test):>6,} images\")\n",
        "    print(f\"\\n   Target Domain (PlantDoc):\")\n",
        "    print(f\"      Train: {len(target_train):>6,} images\")\n",
        "    print(f\"      Val:   {len(target_val):>6,} images\")\n",
        "    print(f\"      Test:  {len(target_test):>6,} images\")\n",
        "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "    return loaders, num_classes, common_names\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Module 1: Data Preprocessing (with class filtering) loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmPdFY-pwAmP",
        "outputId": "08e6abf7-f071-4161-d1f3-b232bcfb3cc1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_preprocessing.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from data_preprocessing import create_data_loaders\n",
        "\n",
        "loaders, num_classes, class_names = create_data_loaders(\n",
        "    plantvillage_path='/content/plantvillage/PlantVillage',  # Note: No /PlantVillage - it auto-detects\n",
        "    plantdoc_path='/content/plantdoc',\n",
        "    batch_size=32,\n",
        "    use_common_classes=True,  # IMPORTANT: Enable filtering\n",
        "    mapping_file='class_mapping.json'  # Must exist (run class_mapper.py first)\n",
        ")\n",
        "\n",
        "# Now you can access the values\n",
        "print(f\"\\n‚úì Number of classes: {num_classes}\")\n",
        "print(f\"‚úì Class names: {class_names[:5] if len(class_names) > 5 else class_names}\")\n",
        "\n",
        "# Access data loaders\n",
        "print(f\"\\n‚úì Data loaders available:\")\n",
        "for key in loaders.keys():\n",
        "    print(f\"   - {key}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roMOoU1GDPV9",
        "outputId": "7e700840-d65e-4ac8-c251-4c568e987d65"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "CREATING FILTERED DATASETS (COMMON CLASSES ONLY)\n",
            "======================================================================\n",
            "\n",
            "üìã Loading class mapping...\n",
            "   Using 9 common classes\n",
            "   Classes: grape black rot, potato early blight, potato late blight, squash powdery mildew, tomato bacterial spot...\n",
            "\n",
            "üìÇ Loading PlantVillage (Source Domain)...\n",
            "  Filtering from 38 to 9 common classes\n",
            "  Loaded 10219 images from 9 classes\n",
            "  Filtering from 38 to 9 common classes\n",
            "  Loaded 1276 images from 9 classes\n",
            "  Filtering from 38 to 9 common classes\n",
            "  Loaded 1279 images from 9 classes\n",
            "\n",
            "üìÇ Loading PlantDoc (Target Domain)...\n",
            "  Filtering from 28 to 9 common classes\n",
            "  Loaded 1063 images from 9 classes\n",
            "  Filtering from 27 to 9 common classes\n",
            "  Loaded 41 images from 9 classes\n",
            "  Filtering from 27 to 9 common classes\n",
            "  Loaded 41 images from 9 classes\n",
            "\n",
            "======================================================================\n",
            "DATASET SUMMARY (FILTERED TO COMMON CLASSES)\n",
            "======================================================================\n",
            "\n",
            "üìä Common Classes: 9\n",
            "\n",
            "   Source Domain (PlantVillage):\n",
            "      Train: 10,219 images\n",
            "      Val:    1,276 images\n",
            "      Test:   1,279 images\n",
            "\n",
            "   Target Domain (PlantDoc):\n",
            "      Train:  1,063 images\n",
            "      Val:       41 images\n",
            "      Test:      41 images\n",
            "\n",
            "======================================================================\n",
            "\n",
            "\n",
            "‚úì Number of classes: 9\n",
            "‚úì Class names: ['grape black rot', 'potato early blight', 'potato late blight', 'squash powdery mildew', 'tomato bacterial spot']\n",
            "\n",
            "‚úì Data loaders available:\n",
            "   - source_train\n",
            "   - source_val\n",
            "   - source_test\n",
            "   - target_train\n",
            "   - target_val\n",
            "   - target_test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODULE 2: MODEL ARCHITECTURE\n",
        "UncertaintyResNet with domain adaptation components"
      ],
      "metadata": {
        "id": "XH8he2BGxgyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_architecture.py\n",
        "\n",
        "\"\"\"\n",
        "MODULE 2: MODEL ARCHITECTURE\n",
        "UncertaintyResNet with domain adaptation components\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from torch.autograd import Function\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class GradientReversalFunction(Function):\n",
        "    \"\"\"Gradient Reversal Layer from DANN (Ganin & Lempitsky, 2015)\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, lambda_):\n",
        "        ctx.lambda_ = lambda_\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output.neg() * ctx.lambda_, None\n",
        "\n",
        "\n",
        "class GradientReversalLayer(nn.Module):\n",
        "    \"\"\"Wrapper for gradient reversal function\"\"\"\n",
        "\n",
        "    def __init__(self, lambda_=1.0):\n",
        "        super(GradientReversalLayer, self).__init__()\n",
        "        self.lambda_ = lambda_\n",
        "\n",
        "    def forward(self, x):\n",
        "        return GradientReversalFunction.apply(x, self.lambda_)\n",
        "\n",
        "    def set_lambda(self, lambda_):\n",
        "        \"\"\"Dynamically adjust lambda during training\"\"\"\n",
        "        self.lambda_ = lambda_\n",
        "\n",
        "\n",
        "class DomainDiscriminator(nn.Module):\n",
        "    \"\"\"Domain discriminator for adversarial domain adaptation\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=2048):\n",
        "        super(DomainDiscriminator, self).__init__()\n",
        "\n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.discriminator(x)\n",
        "\n",
        "\n",
        "class EvidentialClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Evidential classification head using Subjective Logic\n",
        "    Based on Sensoy et al. (2018)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=2048, num_classes=38):\n",
        "        super(EvidentialClassifier, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass producing Dirichlet parameters\n",
        "\n",
        "        Returns:\n",
        "            evidence: Evidence for each class\n",
        "            alpha: Dirichlet parameters\n",
        "            uncertainty: Epistemic uncertainty measure\n",
        "        \"\"\"\n",
        "        logits = self.classifier(x)\n",
        "        evidence = F.softplus(logits)\n",
        "        alpha = evidence + 1.0\n",
        "        S = torch.sum(alpha, dim=1, keepdim=True)\n",
        "        uncertainty = self.num_classes / S\n",
        "\n",
        "        return evidence, alpha, uncertainty\n",
        "\n",
        "    def predict_proba(self, alpha):\n",
        "        \"\"\"Compute predicted class probabilities from Dirichlet parameters\"\"\"\n",
        "        S = torch.sum(alpha, dim=1, keepdim=True)\n",
        "        probs = alpha / S\n",
        "        return probs\n",
        "\n",
        "\n",
        "class UncertaintyResNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Complete uncertainty-aware domain adaptation model\n",
        "    Combines ResNet50 + evidential classifier + domain discriminator\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=38, pretrained=True, freeze_backbone=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_classes: Number of disease classes\n",
        "            pretrained: Whether to use ImageNet pretrained weights\n",
        "            freeze_backbone: Whether to freeze early ResNet layers\n",
        "        \"\"\"\n",
        "        super(UncertaintyResNet, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Load pretrained ResNet50\n",
        "        resnet = models.resnet50(pretrained=pretrained)\n",
        "\n",
        "        # Feature extractor (all layers except final FC)\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            *list(resnet.children())[:-1]\n",
        "        )\n",
        "\n",
        "        # Freeze early layers if specified\n",
        "        if freeze_backbone:\n",
        "            for name, param in self.feature_extractor.named_parameters():\n",
        "                if 'layer4' not in name:\n",
        "                    param.requires_grad = False\n",
        "\n",
        "        # Feature dimension\n",
        "        self.feature_dim = 2048\n",
        "\n",
        "        # Domain adaptation components\n",
        "        self.grl = GradientReversalLayer(lambda_=1.0)\n",
        "        self.domain_discriminator = DomainDiscriminator(self.feature_dim)\n",
        "\n",
        "        # Evidential classifier\n",
        "        self.classifier = EvidentialClassifier(self.feature_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, alpha=1.0):\n",
        "        \"\"\"\n",
        "        Forward pass with optional alpha for GRL\n",
        "\n",
        "        Args:\n",
        "            x: Input images (batch_size, 3, 224, 224)\n",
        "            alpha: Gradient reversal coefficient\n",
        "\n",
        "        Returns:\n",
        "            features, evidence, alpha_params, uncertainty, domain_pred\n",
        "        \"\"\"\n",
        "        # Extract features\n",
        "        features = self.feature_extractor(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "\n",
        "        # Classification path (evidential)\n",
        "        evidence, alpha_params, uncertainty = self.classifier(features)\n",
        "\n",
        "        # Domain discrimination path (with gradient reversal)\n",
        "        self.grl.set_lambda(alpha)\n",
        "        reversed_features = self.grl(features)\n",
        "        domain_pred = self.domain_discriminator(reversed_features)\n",
        "\n",
        "        return features, evidence, alpha_params, uncertainty, domain_pred\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        Make predictions on input images\n",
        "\n",
        "        Returns:\n",
        "            probs, uncertainty, predicted_class\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            _, evidence, alpha, uncertainty, _ = self.forward(x, alpha=0.0)\n",
        "            probs = self.classifier.predict_proba(alpha)\n",
        "            predicted_class = torch.argmax(probs, dim=1)\n",
        "\n",
        "        return probs, uncertainty, predicted_class\n",
        "\n",
        "    def get_num_params(self):\n",
        "        \"\"\"Get total number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def calculate_lambda_schedule(epoch, max_epochs, gamma=10):\n",
        "    \"\"\"\n",
        "    Calculate lambda for gradient reversal layer following DANN paper\n",
        "\n",
        "    Args:\n",
        "        epoch: Current epoch\n",
        "        max_epochs: Total number of epochs\n",
        "        gamma: Adjustment parameter\n",
        "\n",
        "    Returns:\n",
        "        lambda_: Gradient reversal coefficient\n",
        "    \"\"\"\n",
        "    p = epoch / max_epochs\n",
        "    lambda_ = 2.0 / (1.0 + np.exp(-gamma * p)) - 1.0\n",
        "    return lambda_\n",
        "\n",
        "\n",
        "def create_model(num_classes, device='cuda', pretrained=True, freeze_backbone=True):\n",
        "    \"\"\"\n",
        "    Create and initialize the complete model\n",
        "\n",
        "    Args:\n",
        "        num_classes: Number of disease classes\n",
        "        device: Device to place model on\n",
        "        pretrained: Use ImageNet pretrained weights\n",
        "        freeze_backbone: Freeze early ResNet layers\n",
        "\n",
        "    Returns:\n",
        "        model: Initialized model on specified device\n",
        "    \"\"\"\n",
        "    model = UncertaintyResNet(\n",
        "        num_classes=num_classes,\n",
        "        pretrained=pretrained,\n",
        "        freeze_backbone=freeze_backbone\n",
        "    )\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    print(f\"Model created with {model.get_num_params():,} trainable parameters\")\n",
        "    print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7zi42CNDmeL",
        "outputId": "2f742919-1ae4-4819-bc1b-7370ff475619"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_architecture.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODULE 3: LOSS FUNCTIONS\n",
        "Evidential loss, adversarial loss, and combined loss"
      ],
      "metadata": {
        "id": "Rz3nFPFbEFZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile loss_functions.py\n",
        "\n",
        "\"\"\"\n",
        "MODULE 3: LOSS FUNCTIONS\n",
        "Evidential loss, adversarial loss, and combined loss\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class EvidentialLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Evidential classification loss based on subjective logic\n",
        "    From Sensoy et al. (2018)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, lambda_kl=0.1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_classes: Number of classes\n",
        "            lambda_kl: Weight for KL divergence regularization\n",
        "        \"\"\"\n",
        "        super(EvidentialLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.lambda_kl = lambda_kl\n",
        "\n",
        "    def forward(self, evidence, alpha, targets, epoch):\n",
        "        \"\"\"\n",
        "        Compute evidential loss\n",
        "\n",
        "        Args:\n",
        "            evidence: Evidence for each class (batch_size, num_classes)\n",
        "            alpha: Dirichlet parameters (batch_size, num_classes)\n",
        "            targets: True class labels (batch_size,)\n",
        "            epoch: Current epoch (for annealing KL weight)\n",
        "\n",
        "        Returns:\n",
        "            total_loss, classification_loss, kl_loss\n",
        "        \"\"\"\n",
        "        # Convert targets to one-hot\n",
        "        y = F.one_hot(targets, num_classes=self.num_classes).float()\n",
        "\n",
        "        # Sum of Dirichlet parameters\n",
        "        S = torch.sum(alpha, dim=1, keepdim=True)\n",
        "\n",
        "        # Classification loss (Type II maximum likelihood)\n",
        "        classification_loss = torch.sum(\n",
        "            y * (torch.digamma(S) - torch.digamma(alpha)),\n",
        "            dim=1\n",
        "        )\n",
        "        classification_loss = torch.mean(classification_loss)\n",
        "\n",
        "        # KL divergence regularization\n",
        "        alpha_tilde = y + (1 - y) * alpha\n",
        "        S_tilde = torch.sum(alpha_tilde, dim=1, keepdim=True)\n",
        "\n",
        "        kl_loss = self._kl_divergence(alpha_tilde, S_tilde)\n",
        "        kl_loss = torch.mean(kl_loss)\n",
        "\n",
        "        # Anneal KL weight\n",
        "        annealing_coef = min(1.0, epoch / 10.0)\n",
        "        weighted_kl_loss = annealing_coef * self.lambda_kl * kl_loss\n",
        "\n",
        "        # Total loss\n",
        "        total_loss = classification_loss + weighted_kl_loss\n",
        "\n",
        "        return total_loss, classification_loss, kl_loss\n",
        "\n",
        "    def _kl_divergence(self, alpha, S):\n",
        "        \"\"\"Compute KL divergence between Dirichlet distributions\"\"\"\n",
        "        beta = torch.ones_like(alpha)\n",
        "        S_beta = torch.sum(beta, dim=1, keepdim=True)\n",
        "\n",
        "        kl = torch.lgamma(S) - torch.lgamma(S_beta) - torch.sum(\n",
        "            torch.lgamma(alpha) - torch.lgamma(beta), dim=1, keepdim=True\n",
        "        ) + torch.sum(\n",
        "            (alpha - beta) * (torch.digamma(alpha) - torch.digamma(S)),\n",
        "            dim=1, keepdim=True\n",
        "        )\n",
        "\n",
        "        return kl\n",
        "\n",
        "\n",
        "class DomainAdversarialLoss(nn.Module):\n",
        "    \"\"\"Domain adversarial loss for domain confusion\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DomainAdversarialLoss, self).__init__()\n",
        "        self.criterion = nn.BCELoss()\n",
        "\n",
        "    def forward(self, domain_pred, domain_labels):\n",
        "        \"\"\"\n",
        "        Compute domain adversarial loss\n",
        "\n",
        "        Args:\n",
        "            domain_pred: Domain predictions (batch_size, 1)\n",
        "            domain_labels: True domain labels (0=source, 1=target)\n",
        "\n",
        "        Returns:\n",
        "            loss: Domain adversarial loss\n",
        "        \"\"\"\n",
        "        loss = self.criterion(domain_pred, domain_labels)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class CombinedDomainAdaptationLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined loss for uncertainty-aware domain adaptation\n",
        "    L_total = L_cls + lambda_adv * L_adv + lambda_kl * L_kl\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, lambda_adv=1.0, lambda_kl=0.1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_classes: Number of classes\n",
        "            lambda_adv: Weight for adversarial loss\n",
        "            lambda_kl: Weight for KL regularization\n",
        "        \"\"\"\n",
        "        super(CombinedDomainAdaptationLoss, self).__init__()\n",
        "\n",
        "        self.evidential_loss = EvidentialLoss(num_classes, lambda_kl)\n",
        "        self.adversarial_loss = DomainAdversarialLoss()\n",
        "        self.lambda_adv = lambda_adv\n",
        "\n",
        "    def forward(self, evidence, alpha, targets, domain_pred, domain_labels,\n",
        "                epoch, lambda_schedule=1.0):\n",
        "        \"\"\"\n",
        "        Compute combined loss\n",
        "\n",
        "        Args:\n",
        "            evidence: Evidence for each class\n",
        "            alpha: Dirichlet parameters\n",
        "            targets: True class labels\n",
        "            domain_pred: Domain predictions\n",
        "            domain_labels: True domain labels\n",
        "            epoch: Current epoch\n",
        "            lambda_schedule: Scheduled weight for adversarial loss\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing all loss components\n",
        "        \"\"\"\n",
        "        # Classification loss (evidential)\n",
        "        cls_loss, cls_component, kl_component = self.evidential_loss(\n",
        "            evidence, alpha, targets, epoch\n",
        "        )\n",
        "\n",
        "        # Domain adversarial loss\n",
        "        adv_loss = self.adversarial_loss(domain_pred, domain_labels)\n",
        "\n",
        "        # Weighted adversarial loss (with scheduling)\n",
        "        weighted_adv_loss = self.lambda_adv * lambda_schedule * adv_loss\n",
        "\n",
        "        # Total loss\n",
        "        total_loss = cls_loss + weighted_adv_loss\n",
        "\n",
        "        return {\n",
        "            'total': total_loss,\n",
        "            'classification': cls_component,\n",
        "            'kl_divergence': kl_component,\n",
        "            'adversarial': adv_loss,\n",
        "            'weighted_adversarial': weighted_adv_loss\n",
        "        }\n",
        "\n",
        "\n",
        "def calculate_accuracy(predictions, targets):\n",
        "    \"\"\"Calculate classification accuracy\"\"\"\n",
        "    correct = (predictions == targets).sum().item()\n",
        "    total = targets.size(0)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def calculate_expected_calibration_error(probs, targets, n_bins=15):\n",
        "    \"\"\"\n",
        "    Calculate Expected Calibration Error (ECE)\n",
        "    Measures reliability of confidence estimates\n",
        "    \"\"\"\n",
        "    # Get confidence and predictions\n",
        "    confidences, predictions = torch.max(probs, dim=1)\n",
        "    accuracies = (predictions == targets).float()\n",
        "\n",
        "    # Create bins\n",
        "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "    ece = 0.0\n",
        "\n",
        "    for i in range(n_bins):\n",
        "        in_bin = (confidences > bin_boundaries[i]) & (confidences <= bin_boundaries[i + 1])\n",
        "        prop_in_bin = in_bin.float().mean()\n",
        "\n",
        "        if prop_in_bin.item() > 0:\n",
        "            accuracy_in_bin = accuracies[in_bin].mean()\n",
        "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "    return ece.item()\n",
        "\n",
        "\n",
        "class UncertaintyMetrics:\n",
        "    \"\"\"Calculate various uncertainty-related metrics\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def epistemic_uncertainty(alpha):\n",
        "        \"\"\"Calculate epistemic uncertainty from Dirichlet parameters\"\"\"\n",
        "        S = torch.sum(alpha, dim=1)\n",
        "        num_classes = alpha.size(1)\n",
        "        uncertainty = num_classes / S\n",
        "        return uncertainty\n",
        "\n",
        "    @staticmethod\n",
        "    def uncertainty_stratified_accuracy(probs, uncertainty, targets,\n",
        "                                       thresholds=[0.15, 0.35]):\n",
        "        \"\"\"Calculate accuracy for different uncertainty strata\"\"\"\n",
        "        predictions = torch.argmax(probs, dim=1)\n",
        "        correct = (predictions == targets).float()\n",
        "\n",
        "        # High confidence (low uncertainty)\n",
        "        high_conf_mask = uncertainty < thresholds[0]\n",
        "        high_conf_acc = correct[high_conf_mask].mean().item() if high_conf_mask.any() else 0.0\n",
        "        high_conf_count = high_conf_mask.sum().item()\n",
        "\n",
        "        # Medium confidence\n",
        "        med_conf_mask = (uncertainty >= thresholds[0]) & (uncertainty < thresholds[1])\n",
        "        med_conf_acc = correct[med_conf_mask].mean().item() if med_conf_mask.any() else 0.0\n",
        "        med_conf_count = med_conf_mask.sum().item()\n",
        "\n",
        "        # Low confidence (high uncertainty)\n",
        "        low_conf_mask = uncertainty >= thresholds[1]\n",
        "        low_conf_acc = correct[low_conf_mask].mean().item() if low_conf_mask.any() else 0.0\n",
        "        low_conf_count = low_conf_mask.sum().item()\n",
        "\n",
        "        return {\n",
        "            'high_confidence': {\n",
        "                'accuracy': high_conf_acc * 100,\n",
        "                'count': high_conf_count,\n",
        "                'percentage': 100 * high_conf_count / len(uncertainty)\n",
        "            },\n",
        "            'medium_confidence': {\n",
        "                'accuracy': med_conf_acc * 100,\n",
        "                'count': med_conf_count,\n",
        "                'percentage': 100 * med_conf_count / len(uncertainty)\n",
        "            },\n",
        "            'low_confidence': {\n",
        "                'accuracy': low_conf_acc * 100,\n",
        "                'count': low_conf_count,\n",
        "                'percentage': 100 * low_conf_count / len(uncertainty)\n",
        "            }\n",
        "        }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhWju7N1EKYh",
        "outputId": "58e66fa4-25fb-494b-e6d6-3779193340cb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing loss_functions.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODULE 4: TRAINING LOOP\n",
        "Two-stage training procedure with domain adaptation"
      ],
      "metadata": {
        "id": "szNeJja6EduQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile training_loop.py\n",
        "\n",
        "\"\"\"\n",
        "MODULE 4: TRAINING LOOP\n",
        "Two-stage training procedure with domain adaptation\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class DomainAdaptationTrainer:\n",
        "    \"\"\"Trainer for uncertainty-aware domain adaptation\"\"\"\n",
        "\n",
        "    def __init__(self, model, device, num_classes, save_dir='./checkpoints'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model: The UncertaintyResNet model\n",
        "            device: Device to train on\n",
        "            num_classes: Number of classes\n",
        "            save_dir: Directory to save checkpoints\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "        self.save_dir = save_dir\n",
        "\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # Training history\n",
        "        self.history = {\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_acc': [],\n",
        "            'target_val_acc': []\n",
        "        }\n",
        "\n",
        "        self.best_target_acc = 0.0\n",
        "        self.best_epoch = 0\n",
        "\n",
        "    def stage1_pretrain(self, train_loader, val_loader, epochs=30,\n",
        "                       lr=0.001, weight_decay=1e-4, patience=15):\n",
        "        \"\"\"Stage 1: Pre-training on source domain\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"STAGE 1: PRE-TRAINING ON SOURCE DOMAIN\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Import here to avoid circular imports\n",
        "        from loss_functions import EvidentialLoss\n",
        "\n",
        "        # Optimizer and scheduler\n",
        "        optimizer = optim.Adam(\n",
        "            filter(lambda p: p.requires_grad, self.model.parameters()),\n",
        "            lr=lr,\n",
        "            weight_decay=weight_decay\n",
        "        )\n",
        "\n",
        "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "        criterion = EvidentialLoss(self.num_classes, lambda_kl=0.1)\n",
        "\n",
        "        best_val_acc = 0.0\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training\n",
        "            self.model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
        "            for images, labels, _ in pbar:\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                _, evidence, alpha, _, _ = self.model(images, alpha=0.0)\n",
        "\n",
        "                # Compute loss\n",
        "                loss, cls_loss, kl_loss = criterion(evidence, alpha, labels, epoch)\n",
        "\n",
        "                # Backward pass\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                probs = self.model.classifier.predict_proba(alpha)\n",
        "                predictions = torch.argmax(probs, dim=1)\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                train_correct += (predictions == labels).sum().item()\n",
        "                train_total += labels.size(0)\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'loss': f'{loss.item():.4f}',\n",
        "                    'acc': f'{100.0 * train_correct / train_total:.2f}%'\n",
        "                })\n",
        "\n",
        "            # Validation\n",
        "            val_acc = self._validate(val_loader, domain='source')\n",
        "\n",
        "            # Update learning rate\n",
        "            scheduler.step()\n",
        "\n",
        "            # Save metrics\n",
        "            self.history['train_loss'].append(train_loss / len(train_loader))\n",
        "            self.history['train_acc'].append(100.0 * train_correct / train_total)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}: Train Acc = {100.0 * train_correct / train_total:.2f}%, \"\n",
        "                  f\"Val Acc = {val_acc:.2f}%\")\n",
        "\n",
        "            # Early stopping and checkpointing\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                patience_counter = 0\n",
        "                self._save_checkpoint(epoch, val_acc, 'stage1_best.pth')\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Load best model\n",
        "        self._load_checkpoint('stage1_best.pth')\n",
        "        print(f\"\\nStage 1 completed. Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "    def stage2_domain_adaptation(self, source_loader, target_loader,\n",
        "                                 target_val_loader, epochs=50,\n",
        "                                 lr=0.0001, weight_decay=1e-4, patience=15):\n",
        "        \"\"\"Stage 2: Domain adaptation with target domain data\"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"STAGE 2: DOMAIN ADAPTATION\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Import here to avoid circular imports\n",
        "        from loss_functions import CombinedDomainAdaptationLoss\n",
        "        from model_architecture import calculate_lambda_schedule\n",
        "\n",
        "        # Optimizer and scheduler\n",
        "        optimizer = optim.Adam(\n",
        "            filter(lambda p: p.requires_grad, self.model.parameters()),\n",
        "            lr=lr,\n",
        "            weight_decay=weight_decay\n",
        "        )\n",
        "\n",
        "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "        criterion = CombinedDomainAdaptationLoss(self.num_classes, lambda_adv=1.0, lambda_kl=0.1)\n",
        "\n",
        "        best_target_acc = 0.0\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            # Calculate gradient reversal lambda\n",
        "            grl_lambda = calculate_lambda_schedule(epoch, epochs)\n",
        "\n",
        "            # Iterate through both source and target data\n",
        "            source_iter = iter(source_loader)\n",
        "            target_iter = iter(target_loader)\n",
        "\n",
        "            n_batches = min(len(source_loader), len(target_loader))\n",
        "\n",
        "            pbar = tqdm(range(n_batches), desc=f'Epoch {epoch+1}/{epochs}')\n",
        "            for _ in pbar:\n",
        "                # Get source batch\n",
        "                try:\n",
        "                    source_images, source_labels, _ = next(source_iter)\n",
        "                except StopIteration:\n",
        "                    source_iter = iter(source_loader)\n",
        "                    source_images, source_labels, _ = next(source_iter)\n",
        "\n",
        "                # Get target batch\n",
        "                try:\n",
        "                    target_images, _, _ = next(target_iter)\n",
        "                except StopIteration:\n",
        "                    target_iter = iter(target_loader)\n",
        "                    target_images, _, _ = next(target_iter)\n",
        "\n",
        "                source_images = source_images.to(self.device)\n",
        "                source_labels = source_labels.to(self.device)\n",
        "                target_images = target_images.to(self.device)\n",
        "\n",
        "                # Combine source and target\n",
        "                combined_images = torch.cat([source_images, target_images], dim=0)\n",
        "                batch_size_source = source_images.size(0)\n",
        "                batch_size_target = target_images.size(0)\n",
        "\n",
        "                # Domain labels\n",
        "                domain_labels = torch.cat([\n",
        "                    torch.zeros(batch_size_source, 1),\n",
        "                    torch.ones(batch_size_target, 1)\n",
        "                ], dim=0).to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                _, evidence, alpha, _, domain_pred = self.model(\n",
        "                    combined_images, alpha=grl_lambda\n",
        "                )\n",
        "\n",
        "                # Split outputs\n",
        "                source_evidence = evidence[:batch_size_source]\n",
        "                source_alpha = alpha[:batch_size_source]\n",
        "\n",
        "                # Compute combined loss\n",
        "                losses = criterion(\n",
        "                    source_evidence, source_alpha, source_labels,\n",
        "                    domain_pred, domain_labels, epoch, lambda_schedule=grl_lambda\n",
        "                )\n",
        "\n",
        "                # Backward pass\n",
        "                losses['total'].backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                probs = self.model.classifier.predict_proba(source_alpha)\n",
        "                predictions = torch.argmax(probs, dim=1)\n",
        "\n",
        "                train_loss += losses['total'].item()\n",
        "                train_correct += (predictions == source_labels).sum().item()\n",
        "                train_total += source_labels.size(0)\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'loss': f'{losses[\"total\"].item():.4f}',\n",
        "                    'acc': f'{100.0 * train_correct / train_total:.2f}%',\n",
        "                    'lambda': f'{grl_lambda:.3f}'\n",
        "                })\n",
        "\n",
        "            # Validation on target domain\n",
        "            target_val_acc = self._validate(target_val_loader, domain='target')\n",
        "\n",
        "            # Update learning rate\n",
        "            scheduler.step()\n",
        "\n",
        "            # Save metrics\n",
        "            self.history['train_loss'].append(train_loss / n_batches)\n",
        "            self.history['train_acc'].append(100.0 * train_correct / train_total)\n",
        "            self.history['target_val_acc'].append(target_val_acc)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}: Train Acc = {100.0 * train_correct / train_total:.2f}%, \"\n",
        "                  f\"Target Val Acc = {target_val_acc:.2f}%, Lambda = {grl_lambda:.3f}\")\n",
        "\n",
        "            # Early stopping and checkpointing\n",
        "            if target_val_acc > best_target_acc:\n",
        "                best_target_acc = target_val_acc\n",
        "                self.best_target_acc = best_target_acc\n",
        "                self.best_epoch = epoch\n",
        "                patience_counter = 0\n",
        "                self._save_checkpoint(epoch, target_val_acc, 'stage2_best.pth')\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Load best model\n",
        "        self._load_checkpoint('stage2_best.pth')\n",
        "        print(f\"\\nStage 2 completed. Best target validation accuracy: {best_target_acc:.2f}%\")\n",
        "\n",
        "    def _validate(self, val_loader, domain='source'):\n",
        "        \"\"\"Validate model on validation set\"\"\"\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels, _ in val_loader:\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                probs, _, predictions = self.model.predict(images)\n",
        "\n",
        "                correct += (predictions == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        accuracy = 100.0 * correct / total\n",
        "        return accuracy\n",
        "\n",
        "    def _save_checkpoint(self, epoch, accuracy, filename):\n",
        "        \"\"\"Save model checkpoint\"\"\"\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'accuracy': accuracy,\n",
        "            'history': self.history\n",
        "        }\n",
        "        torch.save(checkpoint, os.path.join(self.save_dir, filename))\n",
        "\n",
        "    def _load_checkpoint(self, filename):\n",
        "        \"\"\"Load model checkpoint\"\"\"\n",
        "        checkpoint = torch.load(os.path.join(self.save_dir, filename))\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "def train_model(model, data_loaders, device, num_classes, config):\n",
        "    \"\"\"\n",
        "    Complete training pipeline\n",
        "\n",
        "    Args:\n",
        "        model: The model to train\n",
        "        data_loaders: Dictionary of data loaders\n",
        "        device: Device to train on\n",
        "        num_classes: Number of classes\n",
        "        config: Training configuration dictionary\n",
        "\n",
        "    Returns:\n",
        "        trained model and trainer object\n",
        "    \"\"\"\n",
        "    trainer = DomainAdaptationTrainer(\n",
        "        model=model,\n",
        "        device=device,\n",
        "        num_classes=num_classes,\n",
        "        save_dir=config.get('save_dir', './checkpoints')\n",
        "    )\n",
        "\n",
        "    # Stage 1: Pre-training\n",
        "    trainer.stage1_pretrain(\n",
        "        train_loader=data_loaders['source_train'],\n",
        "        val_loader=data_loaders['source_val'],\n",
        "        epochs=config.get('stage1_epochs', 30),\n",
        "        lr=config.get('stage1_lr', 0.001),\n",
        "        weight_decay=config.get('weight_decay', 1e-4),\n",
        "        patience=config.get('patience', 15)\n",
        "    )\n",
        "\n",
        "    # Stage 2: Domain adaptation\n",
        "    trainer.stage2_domain_adaptation(\n",
        "        source_loader=data_loaders['source_train'],\n",
        "        target_loader=data_loaders['target_train'],\n",
        "        target_val_loader=data_loaders['target_val'],\n",
        "        epochs=config.get('stage2_epochs', 50),\n",
        "        lr=config.get('stage2_lr', 0.0001),\n",
        "        weight_decay=config.get('weight_decay', 1e-4),\n",
        "        patience=config.get('patience', 15)\n",
        "    )\n",
        "\n",
        "    return model, trainer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcOj00QuEiZ2",
        "outputId": "9dba5afa-b2c3-4fc4-def3-7abb0eabf519"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing training_loop.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODULE 5: EVALUATION CODE\n",
        "Comprehensive model evaluation with metrics and visualizations"
      ],
      "metadata": {
        "id": "mJaRWYk7EwyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile evaluation_code.py\n",
        "\n",
        "\"\"\"\n",
        "MODULE 5: EVALUATION CODE\n",
        "Comprehensive model evaluation with metrics and visualizations\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "\n",
        "class ModelEvaluator:\n",
        "    \"\"\"Comprehensive model evaluation\"\"\"\n",
        "\n",
        "    def __init__(self, model, device, class_names=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model: Trained model\n",
        "            device: Device to evaluate on\n",
        "            class_names: List of class names\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.class_names = class_names\n",
        "        self.model.eval()\n",
        "\n",
        "    def evaluate(self, test_loader):\n",
        "        \"\"\"\n",
        "        Comprehensive evaluation on test set\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing all evaluation metrics\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"EVALUATING MODEL\")\n",
        "        print(f\"{'='*60}\\n\")\n",
        "\n",
        "        all_predictions = []\n",
        "        all_targets = []\n",
        "        all_probs = []\n",
        "        all_uncertainties = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels, _ in tqdm(test_loader, desc='Evaluating'):\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                probs, uncertainty, predictions = self.model.predict(images)\n",
        "\n",
        "                all_predictions.extend(predictions.cpu().numpy())\n",
        "                all_targets.extend(labels.cpu().numpy())\n",
        "                all_probs.append(probs.cpu().numpy())\n",
        "                all_uncertainties.extend(uncertainty.squeeze().cpu().numpy())\n",
        "\n",
        "        all_predictions = np.array(all_predictions)\n",
        "        all_targets = np.array(all_targets)\n",
        "        all_probs = np.vstack(all_probs)\n",
        "        all_uncertainties = np.array(all_uncertainties)\n",
        "\n",
        "        # Calculate metrics\n",
        "        results = {\n",
        "            'accuracy': self._calculate_accuracy(all_predictions, all_targets),\n",
        "            'precision_recall_f1': self._calculate_prf1(all_predictions, all_targets),\n",
        "            'confusion_matrix': confusion_matrix(all_targets, all_predictions),\n",
        "            'ece': self._calculate_ece(all_probs, all_targets),\n",
        "            'uncertainty_metrics': self._analyze_uncertainty(\n",
        "                all_probs, all_uncertainties, all_targets\n",
        "            )\n",
        "        }\n",
        "\n",
        "        # Print results\n",
        "        self._print_results(results)\n",
        "\n",
        "        return results, all_predictions, all_targets, all_probs, all_uncertainties\n",
        "\n",
        "    def _calculate_accuracy(self, predictions, targets):\n",
        "        \"\"\"Calculate overall accuracy\"\"\"\n",
        "        correct = (predictions == targets).sum()\n",
        "        total = len(targets)\n",
        "        accuracy = 100.0 * correct / total\n",
        "        return accuracy\n",
        "\n",
        "    def _calculate_prf1(self, predictions, targets):\n",
        "        \"\"\"Calculate precision, recall, F1-score\"\"\"\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            targets, predictions, average='macro', zero_division=0\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1\n",
        "        }\n",
        "\n",
        "    def _calculate_ece(self, probs, targets, n_bins=15):\n",
        "        \"\"\"Calculate Expected Calibration Error\"\"\"\n",
        "        confidences = np.max(probs, axis=1)\n",
        "        predictions = np.argmax(probs, axis=1)\n",
        "        accuracies = (predictions == targets).astype(float)\n",
        "\n",
        "        bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "        ece = 0.0\n",
        "\n",
        "        for i in range(n_bins):\n",
        "            in_bin = (confidences > bin_boundaries[i]) & (confidences <= bin_boundaries[i + 1])\n",
        "            prop_in_bin = in_bin.mean()\n",
        "\n",
        "            if prop_in_bin > 0:\n",
        "                accuracy_in_bin = accuracies[in_bin].mean()\n",
        "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "                ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "        return ece\n",
        "\n",
        "    def _analyze_uncertainty(self, probs, uncertainties, targets,\n",
        "                            thresholds=[0.15, 0.35]):\n",
        "        \"\"\"Analyze uncertainty-stratified performance\"\"\"\n",
        "        predictions = np.argmax(probs, axis=1)\n",
        "        correct = (predictions == targets).astype(float)\n",
        "\n",
        "        # High confidence\n",
        "        high_conf_mask = uncertainties < thresholds[0]\n",
        "        high_conf_acc = correct[high_conf_mask].mean() if high_conf_mask.any() else 0.0\n",
        "        high_conf_count = high_conf_mask.sum()\n",
        "\n",
        "        # Medium confidence\n",
        "        med_conf_mask = (uncertainties >= thresholds[0]) & (uncertainties < thresholds[1])\n",
        "        med_conf_acc = correct[med_conf_mask].mean() if med_conf_mask.any() else 0.0\n",
        "        med_conf_count = med_conf_mask.sum()\n",
        "\n",
        "        # Low confidence\n",
        "        low_conf_mask = uncertainties >= thresholds[1]\n",
        "        low_conf_acc = correct[low_conf_mask].mean() if low_conf_mask.any() else 0.0\n",
        "        low_conf_count = low_conf_mask.sum()\n",
        "\n",
        "        total = len(uncertainties)\n",
        "\n",
        "        return {\n",
        "            'high_confidence': {\n",
        "                'accuracy': high_conf_acc * 100,\n",
        "                'count': int(high_conf_count),\n",
        "                'percentage': 100 * high_conf_count / total\n",
        "            },\n",
        "            'medium_confidence': {\n",
        "                'accuracy': med_conf_acc * 100,\n",
        "                'count': int(med_conf_count),\n",
        "                'percentage': 100 * med_conf_count / total\n",
        "            },\n",
        "            'low_confidence': {\n",
        "                'accuracy': low_conf_acc * 100,\n",
        "                'count': int(low_conf_count),\n",
        "                'percentage': 100 * low_conf_count / total\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _print_results(self, results):\n",
        "        \"\"\"Print evaluation results\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"EVALUATION RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"\\nOverall Accuracy: {results['accuracy']:.2f}%\")\n",
        "\n",
        "        prf = results['precision_recall_f1']\n",
        "        print(f\"Precision (Macro): {prf['precision']:.4f}\")\n",
        "        print(f\"Recall (Macro): {prf['recall']:.4f}\")\n",
        "        print(f\"F1-Score (Macro): {prf['f1_score']:.4f}\")\n",
        "\n",
        "        print(f\"\\nExpected Calibration Error: {results['ece']:.4f}\")\n",
        "\n",
        "        print(\"\\nUncertainty-Stratified Performance:\")\n",
        "        for conf_level, metrics in results['uncertainty_metrics'].items():\n",
        "            print(f\"  {conf_level.replace('_', ' ').title()}:\")\n",
        "            print(f\"    Accuracy: {metrics['accuracy']:.2f}%\")\n",
        "            print(f\"    Samples: {metrics['count']} ({metrics['percentage']:.1f}%)\")\n",
        "\n",
        "    def plot_confusion_matrix(self, confusion_mat, save_path='confusion_matrix.png'):\n",
        "        \"\"\"Plot confusion matrix\"\"\"\n",
        "        plt.figure(figsize=(12, 10))\n",
        "\n",
        "        # Normalize\n",
        "        confusion_mat = confusion_mat.astype('float') / confusion_mat.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        sns.heatmap(\n",
        "            confusion_mat,\n",
        "            annot=False,\n",
        "            fmt='.2f',\n",
        "            cmap='Blues',\n",
        "            square=True,\n",
        "            cbar_kws={'label': 'Proportion'}\n",
        "        )\n",
        "\n",
        "        plt.title('Normalized Confusion Matrix', fontsize=16, fontweight='bold')\n",
        "        plt.ylabel('True Label', fontsize=12)\n",
        "        plt.xlabel('Predicted Label', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"\\nConfusion matrix saved to {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_calibration_curve(self, probs, targets, save_path='calibration_curve.png'):\n",
        "        \"\"\"Plot reliability diagram\"\"\"\n",
        "        confidences = np.max(probs, axis=1)\n",
        "        predictions = np.argmax(probs, axis=1)\n",
        "        accuracies = (predictions == targets).astype(float)\n",
        "\n",
        "        n_bins = 15\n",
        "        bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
        "\n",
        "        bin_accuracies = []\n",
        "        bin_confidences = []\n",
        "\n",
        "        for i in range(n_bins):\n",
        "            in_bin = (confidences > bin_boundaries[i]) & (confidences <= bin_boundaries[i + 1])\n",
        "            if in_bin.sum() > 0:\n",
        "                bin_accuracies.append(accuracies[in_bin].mean())\n",
        "                bin_confidences.append(confidences[in_bin].mean())\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "        # Calibration curve\n",
        "        axes[0].plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
        "        axes[0].plot(bin_confidences, bin_accuracies, 'o-', label='Model Calibration')\n",
        "        axes[0].set_xlabel('Confidence', fontsize=12)\n",
        "        axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "        axes[0].set_title('Reliability Diagram', fontsize=14, fontweight='bold')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Confidence histogram\n",
        "        axes[1].hist(confidences, bins=n_bins, edgecolor='black', alpha=0.7)\n",
        "        axes[1].set_xlabel('Confidence', fontsize=12)\n",
        "        axes[1].set_ylabel('Count', fontsize=12)\n",
        "        axes[1].set_title('Confidence Distribution', fontsize=14, fontweight='bold')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Calibration curve saved to {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "    def plot_uncertainty_distribution(self, uncertainties, predictions, targets,\n",
        "                                     save_path='uncertainty_distribution.png'):\n",
        "        \"\"\"Plot uncertainty distribution\"\"\"\n",
        "        correct_mask = predictions == targets\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "        # Histogram\n",
        "        axes[0].hist(uncertainties[correct_mask], bins=30, alpha=0.6,\n",
        "                    label='Correct', color='green', edgecolor='black')\n",
        "        axes[0].hist(uncertainties[~correct_mask], bins=30, alpha=0.6,\n",
        "                    label='Incorrect', color='red', edgecolor='black')\n",
        "        axes[0].set_xlabel('Uncertainty', fontsize=12)\n",
        "        axes[0].set_ylabel('Count', fontsize=12)\n",
        "        axes[0].set_title('Uncertainty Distribution', fontsize=14, fontweight='bold')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Box plot\n",
        "        data = [uncertainties[correct_mask], uncertainties[~correct_mask]]\n",
        "        axes[1].boxplot(data, labels=['Correct', 'Incorrect'])\n",
        "        axes[1].set_ylabel('Uncertainty', fontsize=12)\n",
        "        axes[1].set_title('Uncertainty Comparison', fontsize=14, fontweight='bold')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Uncertainty distribution saved to {save_path}\")\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def evaluate_model(model, test_loader, device, class_names=None, save_dir='./results'):\n",
        "    \"\"\"\n",
        "    Complete model evaluation with all visualizations\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        test_loader: Test data loader\n",
        "        device: Device to evaluate on\n",
        "        class_names: List of class names\n",
        "        save_dir: Directory to save results\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with all evaluation results\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    evaluator = ModelEvaluator(model, device, class_names)\n",
        "\n",
        "    # Run evaluation\n",
        "    results, predictions, targets, probs, uncertainties = evaluator.evaluate(test_loader)\n",
        "\n",
        "    # Generate visualizations\n",
        "    print(\"\\nGenerating visualizations...\")\n",
        "\n",
        "    evaluator.plot_confusion_matrix(\n",
        "        results['confusion_matrix'],\n",
        "        save_path=os.path.join(save_dir, 'confusion_matrix.png')\n",
        "    )\n",
        "\n",
        "    evaluator.plot_calibration_curve(\n",
        "        probs, targets,\n",
        "        save_path=os.path.join(save_dir, 'calibration_curve.png')\n",
        "    )\n",
        "\n",
        "    evaluator.plot_uncertainty_distribution(\n",
        "        uncertainties, predictions, targets,\n",
        "        save_path=os.path.join(save_dir, 'uncertainty_distribution.png')\n",
        "    )\n",
        "\n",
        "    print(f\"\\nAll evaluation results saved to {save_dir}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVOM84VGE1cp",
        "outputId": "29e88de8-6798-4d39-be26-0e61448bcb09"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluation_code.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete Pipeline"
      ],
      "metadata": {
        "id": "wkwld03LFClE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all modules exist\n",
        "import os\n",
        "modules = ['data_preprocessing', 'model_architecture', 'loss_functions',\n",
        "           'training_loop', 'evaluation_code']\n",
        "for m in modules:\n",
        "    print(f\"{'‚úì' if os.path.exists(f'{m}.py') else '‚úó'} {m}.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDISwLYwEwEZ",
        "outputId": "050846d1-1d8a-4c29-aa8a-2b0be8ebe6b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì data_preprocessing.py\n",
            "‚úì model_architecture.py\n",
            "‚úì loss_functions.py\n",
            "‚úì training_loop.py\n",
            "‚úì evaluation_code.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "COMPLETE EXECUTION SCRIPT - WITH COMMON CLASS FILTERING\n",
        "This version only trains on classes that exist in both datasets\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"UNCERTAINTY-AWARE DOMAIN ADAPTATION (COMMON CLASSES)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 0: CHECK CLASS MAPPING EXISTS\n",
        "# ============================================================================\n",
        "\n",
        "if not os.path.exists('class_mapping.json'):\n",
        "    print(\"\\n‚ùå ERROR: class_mapping.json not found!\")\n",
        "    print(\"\\n‚ö†Ô∏è  You must run the Class Mapping Analysis first:\")\n",
        "    print(\"   1. Save and run class_mapper.py\")\n",
        "    print(\"   2. Review the common classes found\")\n",
        "    print(\"   3. Then run this script\")\n",
        "    raise FileNotFoundError(\"Run class_mapper.py first!\")\n",
        "\n",
        "# Load mapping to show info\n",
        "with open('class_mapping.json', 'r') as f:\n",
        "    mapping_data = json.load(f)\n",
        "\n",
        "print(f\"\\nüìã Class Mapping Info:\")\n",
        "print(f\"   Common classes found: {mapping_data['num_classes']}\")\n",
        "print(f\"   PlantVillage total: {mapping_data['plantvillage_total']}\")\n",
        "print(f\"   PlantDoc total: {mapping_data['plantdoc_total']}\")\n",
        "print(f\"   Match rate: {100*mapping_data['num_classes']/min(mapping_data['plantvillage_total'], mapping_data['plantdoc_total']):.1f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "PLANTVILLAGE_PATH = '/content/plantvillage/PlantVillage'\n",
        "PLANTDOC_PATH = '/content/plantdoc'\n",
        "\n",
        "# TRAINING SETTINGS\n",
        "STAGE1_EPOCHS = 15\n",
        "STAGE2_EPOCHS = 25\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE_STAGE1 = 0.001\n",
        "LEARNING_RATE_STAGE2 = 0.0001\n",
        "WEIGHT_DECAY = 1e-4\n",
        "PATIENCE = 10\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è  Training Configuration:\")\n",
        "print(f\"   Stage 1 epochs: {STAGE1_EPOCHS}\")\n",
        "print(f\"   Stage 2 epochs: {STAGE2_EPOCHS}\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SETUP\n",
        "# ============================================================================\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nüñ•Ô∏è  Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "os.makedirs('./checkpoints', exist_ok=True)\n",
        "os.makedirs('./results', exist_ok=True)\n",
        "\n",
        "# ============================================================================\n",
        "# IMPORT MODULES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"IMPORTING MODULES\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "try:\n",
        "    from data_preprocessing import create_data_loaders\n",
        "    print(\"‚úì data_preprocessing (with class filtering)\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚úó Error: {e}\")\n",
        "    print(\"\\n‚ö†Ô∏è  Make sure you've saved the UPDATED Module 1\")\n",
        "    raise\n",
        "\n",
        "try:\n",
        "    from model_architecture import create_model\n",
        "    print(\"‚úì model_architecture\")\n",
        "except ImportError:\n",
        "    print(\"‚úó model_architecture not found\")\n",
        "    raise\n",
        "\n",
        "try:\n",
        "    from training_loop import train_model\n",
        "    print(\"‚úì training_loop\")\n",
        "except ImportError:\n",
        "    print(\"‚úó training_loop not found\")\n",
        "    raise\n",
        "\n",
        "try:\n",
        "    from evaluation_code import evaluate_model\n",
        "    print(\"‚úì evaluation_code\")\n",
        "except ImportError:\n",
        "    print(\"‚úó evaluation_code not found\")\n",
        "    raise\n",
        "\n",
        "# ============================================================================\n",
        "# CREATE DATA LOADERS (WITH CLASS FILTERING)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CREATING DATA LOADERS (FILTERED TO COMMON CLASSES)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "data_loaders, NUM_CLASSES, common_names = create_data_loaders(\n",
        "    plantvillage_path=PLANTVILLAGE_PATH,\n",
        "    plantdoc_path=PLANTDOC_PATH,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    use_common_classes=True,  # KEY: Enable class filtering\n",
        "    mapping_file='class_mapping.json'\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úì Loaded filtered datasets with {NUM_CLASSES} common classes\")\n",
        "\n",
        "# ============================================================================\n",
        "# CREATE MODEL\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CREATING MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model = create_model(\n",
        "    num_classes=NUM_CLASSES,  # Uses only common classes\n",
        "    device=device,\n",
        "    pretrained=True,\n",
        "    freeze_backbone=True\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úì Model created with {NUM_CLASSES} output classes\")\n",
        "\n",
        "# ============================================================================\n",
        "# TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "approx_time = (STAGE1_EPOCHS * 2) + (STAGE2_EPOCHS * 3)\n",
        "print(f\"\\n‚è±Ô∏è  Estimated time: ~{approx_time} minutes\")\n",
        "print(f\"üöÄ Starting training...\\n\")\n",
        "\n",
        "config = {\n",
        "    'stage1_epochs': STAGE1_EPOCHS,\n",
        "    'stage2_epochs': STAGE2_EPOCHS,\n",
        "    'stage1_lr': LEARNING_RATE_STAGE1,\n",
        "    'stage2_lr': LEARNING_RATE_STAGE2,\n",
        "    'weight_decay': WEIGHT_DECAY,\n",
        "    'patience': PATIENCE,\n",
        "    'save_dir': './checkpoints'\n",
        "}\n",
        "\n",
        "try:\n",
        "    model, trainer = train_model(\n",
        "        model=model,\n",
        "        data_loaders=data_loaders,\n",
        "        device=device,\n",
        "        num_classes=NUM_CLASSES,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚úì TRAINING COMPLETED\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"   Best target accuracy: {trainer.best_target_acc:.2f}%\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚úó Training error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "# ============================================================================\n",
        "# EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EVALUATING MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "try:\n",
        "    results = evaluate_model(\n",
        "        model=model,\n",
        "        test_loader=data_loaders['target_test'],\n",
        "        device=device,\n",
        "        class_names=common_names,  # Pass common class names\n",
        "        save_dir='./results'\n",
        "    )\n",
        "\n",
        "    print(\"\\n‚úì Evaluation completed\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚úó Evaluation error: {e}\")\n",
        "    raise\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéâ EXPERIMENT COMPLETED!\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nüìä Dataset Info:\")\n",
        "print(f\"   Common classes used: {NUM_CLASSES}\")\n",
        "print(f\"   Class names: {', '.join(common_names[:5])}...\")\n",
        "\n",
        "print(f\"\\nüìà Results:\")\n",
        "print(f\"   Target Accuracy: {results['accuracy']:.2f}%\")\n",
        "print(f\"   Precision: {results['precision_recall_f1']['precision']:.4f}\")\n",
        "print(f\"   Recall: {results['precision_recall_f1']['recall']:.4f}\")\n",
        "print(f\"   F1-Score: {results['precision_recall_f1']['f1_score']:.4f}\")\n",
        "print(f\"   ECE: {results['ece']:.4f}\")\n",
        "\n",
        "print(f\"\\nüíæ Saved Files:\")\n",
        "print(f\"   class_mapping.json - Class mapping used\")\n",
        "print(f\"   ./checkpoints/stage1_best.pth\")\n",
        "print(f\"   ./checkpoints/stage2_best.pth\")\n",
        "print(f\"   ./results/confusion_matrix.png\")\n",
        "print(f\"   ./results/calibration_curve.png\")\n",
        "print(f\"   ./results/uncertainty_distribution.png\")\n",
        "\n",
        "# Save detailed summary\n",
        "with open('./results/experiment_summary.txt', 'w') as f:\n",
        "    f.write(\"EXPERIMENT SUMMARY (COMMON CLASSES)\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "    f.write(f\"Dataset Configuration:\\n\")\n",
        "    f.write(f\"  Common classes: {NUM_CLASSES}\\n\")\n",
        "    f.write(f\"  Class names: {', '.join(common_names)}\\n\\n\")\n",
        "    f.write(f\"Training Configuration:\\n\")\n",
        "    f.write(f\"  Stage 1 epochs: {STAGE1_EPOCHS}\\n\")\n",
        "    f.write(f\"  Stage 2 epochs: {STAGE2_EPOCHS}\\n\\n\")\n",
        "    f.write(f\"Results:\\n\")\n",
        "    f.write(f\"  Accuracy: {results['accuracy']:.2f}%\\n\")\n",
        "    f.write(f\"  Precision: {results['precision_recall_f1']['precision']:.4f}\\n\")\n",
        "    f.write(f\"  Recall: {results['precision_recall_f1']['recall']:.4f}\\n\")\n",
        "    f.write(f\"  F1-Score: {results['precision_recall_f1']['f1_score']:.4f}\\n\")\n",
        "    f.write(f\"  ECE: {results['ece']:.4f}\\n\")\n",
        "\n",
        "print(f\"\\n‚úì Detailed summary saved to ./results/experiment_summary.txt\")\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPZPskf8E7K7",
        "outputId": "3300efac-e376-406b-c581-67feac186ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "UNCERTAINTY-AWARE DOMAIN ADAPTATION (COMMON CLASSES)\n",
            "================================================================================\n",
            "\n",
            "üìã Class Mapping Info:\n",
            "   Common classes found: 9\n",
            "   PlantVillage total: 38\n",
            "   PlantDoc total: 28\n",
            "   Match rate: 32.1%\n",
            "\n",
            "‚öôÔ∏è  Training Configuration:\n",
            "   Stage 1 epochs: 15\n",
            "   Stage 2 epochs: 25\n",
            "   Batch size: 32\n",
            "\n",
            "üñ•Ô∏è  Device: cuda\n",
            "   GPU: Tesla T4\n",
            "\n",
            "================================================================================\n",
            "IMPORTING MODULES\n",
            "================================================================================\n",
            "\n",
            "‚úì data_preprocessing (with class filtering)\n",
            "‚úì model_architecture\n",
            "‚úì training_loop\n",
            "‚úì evaluation_code\n",
            "\n",
            "================================================================================\n",
            "CREATING DATA LOADERS (FILTERED TO COMMON CLASSES)\n",
            "================================================================================\n",
            "\n",
            "======================================================================\n",
            "CREATING FILTERED DATASETS (COMMON CLASSES ONLY)\n",
            "======================================================================\n",
            "\n",
            "üìã Loading class mapping...\n",
            "   Using 9 common classes\n",
            "   Classes: grape black rot, potato early blight, potato late blight, squash powdery mildew, tomato bacterial spot...\n",
            "\n",
            "üìÇ Loading PlantVillage (Source Domain)...\n",
            "  Filtering from 38 to 9 common classes\n",
            "  Loaded 10219 images from 9 classes\n",
            "  Filtering from 38 to 9 common classes\n",
            "  Loaded 1276 images from 9 classes\n",
            "  Filtering from 38 to 9 common classes\n",
            "  Loaded 1279 images from 9 classes\n",
            "\n",
            "üìÇ Loading PlantDoc (Target Domain)...\n",
            "  Filtering from 28 to 9 common classes\n",
            "  Loaded 1063 images from 9 classes\n",
            "  Filtering from 27 to 9 common classes\n",
            "  Loaded 41 images from 9 classes\n",
            "  Filtering from 27 to 9 common classes\n",
            "  Loaded 41 images from 9 classes\n",
            "\n",
            "======================================================================\n",
            "DATASET SUMMARY (FILTERED TO COMMON CLASSES)\n",
            "======================================================================\n",
            "\n",
            "üìä Common Classes: 9\n",
            "\n",
            "   Source Domain (PlantVillage):\n",
            "      Train: 10,219 images\n",
            "      Val:    1,276 images\n",
            "      Test:   1,279 images\n",
            "\n",
            "   Target Domain (PlantDoc):\n",
            "      Train:  1,063 images\n",
            "      Val:       41 images\n",
            "      Test:      41 images\n",
            "\n",
            "======================================================================\n",
            "\n",
            "\n",
            "‚úì Loaded filtered datasets with 9 common classes\n",
            "\n",
            "================================================================================\n",
            "CREATING MODEL\n",
            "================================================================================\n",
            "Model created with 2,236,938 trainable parameters\n",
            "Number of classes: 9\n",
            "\n",
            "‚úì Model created with 9 output classes\n",
            "\n",
            "================================================================================\n",
            "TRAINING MODEL\n",
            "================================================================================\n",
            "\n",
            "‚è±Ô∏è  Estimated time: ~105 minutes\n",
            "üöÄ Starting training...\n",
            "\n",
            "\n",
            "============================================================\n",
            "STAGE 1: PRE-TRAINING ON SOURCE DOMAIN\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:27<00:00,  3.64it/s, loss=0.8828, acc=81.33%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc = 81.33%, Val Acc = 86.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:25<00:00,  3.74it/s, loss=0.6614, acc=86.94%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Acc = 86.94%, Val Acc = 90.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:25<00:00,  3.71it/s, loss=0.6006, acc=88.10%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Acc = 88.10%, Val Acc = 89.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:26<00:00,  3.69it/s, loss=0.4862, acc=88.94%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Acc = 88.94%, Val Acc = 90.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:25<00:00,  3.73it/s, loss=0.5813, acc=89.77%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Acc = 89.77%, Val Acc = 91.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:26<00:00,  3.68it/s, loss=0.6629, acc=90.49%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Acc = 90.49%, Val Acc = 91.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:25<00:00,  3.72it/s, loss=0.6114, acc=90.87%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Acc = 90.87%, Val Acc = 92.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:25<00:00,  3.72it/s, loss=0.5178, acc=91.79%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Acc = 91.79%, Val Acc = 93.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:25<00:00,  3.72it/s, loss=0.4310, acc=91.52%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Acc = 91.52%, Val Acc = 93.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:26<00:00,  3.70it/s, loss=0.4327, acc=91.96%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Acc = 91.96%, Val Acc = 93.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:25<00:00,  3.73it/s, loss=0.6151, acc=90.38%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Acc = 90.38%, Val Acc = 90.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:25<00:00,  3.73it/s, loss=0.6578, acc=90.37%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Acc = 90.37%, Val Acc = 92.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:26<00:00,  3.70it/s, loss=0.5453, acc=90.68%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Acc = 90.68%, Val Acc = 91.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:25<00:00,  3.72it/s, loss=0.6607, acc=90.76%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Acc = 90.76%, Val Acc = 91.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 319/319 [01:26<00:00,  3.67it/s, loss=0.4611, acc=91.08%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Acc = 91.08%, Val Acc = 93.03%\n",
            "\n",
            "Stage 1 completed. Best validation accuracy: 93.34%\n",
            "\n",
            "============================================================\n",
            "STAGE 2: DOMAIN ADAPTATION\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:41<00:00,  1.58it/s, loss=0.7212, acc=90.39%, lambda=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc = 90.39%, Target Val Acc = 39.02%, Lambda = 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:42<00:00,  1.55it/s, loss=0.5481, acc=92.71%, lambda=0.197]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Acc = 92.71%, Target Val Acc = 36.59%, Lambda = 0.197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:41<00:00,  1.60it/s, loss=0.3942, acc=92.28%, lambda=0.380]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Acc = 92.28%, Target Val Acc = 34.15%, Lambda = 0.380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:41<00:00,  1.61it/s, loss=0.4679, acc=92.23%, lambda=0.537]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Acc = 92.23%, Target Val Acc = 39.02%, Lambda = 0.537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:42<00:00,  1.56it/s, loss=0.5176, acc=91.71%, lambda=0.664]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Acc = 91.71%, Target Val Acc = 41.46%, Lambda = 0.664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:41<00:00,  1.60it/s, loss=0.4587, acc=92.61%, lambda=0.762]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Acc = 92.61%, Target Val Acc = 39.02%, Lambda = 0.762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:41<00:00,  1.61it/s, loss=0.4550, acc=92.00%, lambda=0.834]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Acc = 92.00%, Target Val Acc = 39.02%, Lambda = 0.834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:42<00:00,  1.55it/s, loss=0.4800, acc=92.23%, lambda=0.885]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Acc = 92.23%, Target Val Acc = 41.46%, Lambda = 0.885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:41<00:00,  1.60it/s, loss=0.3703, acc=92.90%, lambda=0.922]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Acc = 92.90%, Target Val Acc = 36.59%, Lambda = 0.922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:41<00:00,  1.57it/s, loss=0.4171, acc=92.90%, lambda=0.947]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Acc = 92.90%, Target Val Acc = 36.59%, Lambda = 0.947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:41<00:00,  1.60it/s, loss=0.7071, acc=93.28%, lambda=0.964]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Acc = 93.28%, Target Val Acc = 39.02%, Lambda = 0.964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:41<00:00,  1.59it/s, loss=0.5231, acc=93.13%, lambda=0.976]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Acc = 93.13%, Target Val Acc = 36.59%, Lambda = 0.976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:42<00:00,  1.56it/s, loss=0.6778, acc=93.09%, lambda=0.984]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Acc = 93.09%, Target Val Acc = 36.59%, Lambda = 0.984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:41<00:00,  1.58it/s, loss=0.4532, acc=91.86%, lambda=0.989]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Acc = 91.86%, Target Val Acc = 36.59%, Lambda = 0.989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66/66 [00:41<00:00,  1.60it/s, loss=0.6095, acc=92.42%, lambda=0.993]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Acc = 92.42%, Target Val Acc = 39.02%, Lambda = 0.993\n",
            "Early stopping at epoch 15\n",
            "\n",
            "Stage 2 completed. Best target validation accuracy: 41.46%\n",
            "\n",
            "================================================================================\n",
            "‚úì TRAINING COMPLETED\n",
            "================================================================================\n",
            "   Best target accuracy: 41.46%\n",
            "\n",
            "================================================================================\n",
            "EVALUATING MODEL\n",
            "================================================================================\n",
            "\n",
            "============================================================\n",
            "EVALUATING MODEL\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "EVALUATION RESULTS\n",
            "============================================================\n",
            "\n",
            "Overall Accuracy: 46.34%\n",
            "Precision (Macro): 0.5838\n",
            "Recall (Macro): 0.4407\n",
            "F1-Score (Macro): 0.4622\n",
            "\n",
            "Expected Calibration Error: 0.2306\n",
            "\n",
            "Uncertainty-Stratified Performance:\n",
            "  High Confidence:\n",
            "    Accuracy: 100.00%\n",
            "    Samples: 2 (4.9%)\n",
            "  Medium Confidence:\n",
            "    Accuracy: 56.52%\n",
            "    Samples: 23 (56.1%)\n",
            "  Low Confidence:\n",
            "    Accuracy: 25.00%\n",
            "    Samples: 16 (39.0%)\n",
            "\n",
            "Generating visualizations...\n",
            "\n",
            "Confusion matrix saved to ./results/confusion_matrix.png\n",
            "Calibration curve saved to ./results/calibration_curve.png\n",
            "Uncertainty distribution saved to ./results/uncertainty_distribution.png\n",
            "\n",
            "All evaluation results saved to ./results\n",
            "\n",
            "‚úì Evaluation completed\n",
            "\n",
            "================================================================================\n",
            "üéâ EXPERIMENT COMPLETED!\n",
            "================================================================================\n",
            "\n",
            "üìä Dataset Info:\n",
            "   Common classes used: 9\n",
            "   Class names: grape black rot, potato early blight, potato late blight, squash powdery mildew, tomato bacterial spot...\n",
            "\n",
            "üìà Results:\n",
            "   Target Accuracy: 46.34%\n",
            "   Precision: 0.5838\n",
            "   Recall: 0.4407\n",
            "   F1-Score: 0.4622\n",
            "   ECE: 0.2306\n",
            "\n",
            "üíæ Saved Files:\n",
            "   class_mapping.json - Class mapping used\n",
            "   ./checkpoints/stage1_best.pth\n",
            "   ./checkpoints/stage2_best.pth\n",
            "   ./results/confusion_matrix.png\n",
            "   ./results/calibration_curve.png\n",
            "   ./results/uncertainty_distribution.png\n",
            "\n",
            "‚úì Detailed summary saved to ./results/experiment_summary.txt\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}